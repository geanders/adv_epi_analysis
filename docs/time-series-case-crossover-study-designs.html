<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Time series / case-crossover study designs | Advanced Epidemiological Analysis</title>
  <meta name="description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Time series / case-crossover study designs | Advanced Epidemiological Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Time series / case-crossover study designs | Advanced Epidemiological Analysis" />
  
  <meta name="twitter:description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  

<meta name="author" content="Andreas M. Neophytou and G. Brooke Anderson" />


<meta name="date" content="2021-05-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="courseinfo.html"/>
<link rel="next" href="generalized-linear-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Epidemiological Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.1</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="courseinfo.html"><a href="courseinfo.html"><i class="fa fa-check"></i><b>2</b> Course information</a><ul>
<li class="chapter" data-level="2.1" data-path="courseinfo.html"><a href="courseinfo.html#course-learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Course learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="courseinfo.html"><a href="courseinfo.html#meeting-time-and-place"><i class="fa fa-check"></i><b>2.2</b> Meeting time and place</a></li>
<li class="chapter" data-level="2.3" data-path="courseinfo.html"><a href="courseinfo.html#class-structure-and-expectations"><i class="fa fa-check"></i><b>2.3</b> Class Structure and Expectations</a></li>
<li class="chapter" data-level="2.4" data-path="courseinfo.html"><a href="courseinfo.html#course-grading"><i class="fa fa-check"></i><b>2.4</b> Course grading</a></li>
<li class="chapter" data-level="2.5" data-path="courseinfo.html"><a href="courseinfo.html#textbooks-and-course-materials"><i class="fa fa-check"></i><b>2.5</b> Textbooks and Course Materials</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="time-series-case-crossover-study-designs.html"><a href="time-series-case-crossover-study-designs.html"><i class="fa fa-check"></i><b>3</b> Time series / case-crossover study designs</a><ul>
<li class="chapter" data-level="3.1" data-path="time-series-case-crossover-study-designs.html"><a href="time-series-case-crossover-study-designs.html#reading"><i class="fa fa-check"></i><b>3.1</b> Reading</a></li>
<li class="chapter" data-level="3.2" data-path="time-series-case-crossover-study-designs.html"><a href="time-series-case-crossover-study-designs.html#time-series-data"><i class="fa fa-check"></i><b>3.2</b> Time series data</a></li>
<li class="chapter" data-level="3.3" data-path="time-series-case-crossover-study-designs.html"><a href="time-series-case-crossover-study-designs.html#fitting-models"><i class="fa fa-check"></i><b>3.3</b> Fitting models</a></li>
<li class="chapter" data-level="3.4" data-path="time-series-case-crossover-study-designs.html"><a href="time-series-case-crossover-study-designs.html#chapter-vocabulary"><i class="fa fa-check"></i><b>3.4</b> Chapter vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4</b> Generalized linear models</a><ul>
<li class="chapter" data-level="4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#splines-in-glms"><i class="fa fa-check"></i><b>4.1</b> Splines in GLMs</a></li>
<li class="chapter" data-level="4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#cross-basis-functions-in-glms"><i class="fa fa-check"></i><b>4.2</b> Cross-basis functions in GLMs</a></li>
<li class="chapter" data-level="4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#chapter-vocabulary-1"><i class="fa fa-check"></i><b>4.3</b> Chapter vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="natural-experiments.html"><a href="natural-experiments.html"><i class="fa fa-check"></i><b>5</b> Natural experiments</a><ul>
<li class="chapter" data-level="5.1" data-path="natural-experiments.html"><a href="natural-experiments.html#interrupted-time-series"><i class="fa fa-check"></i><b>5.1</b> Interrupted time series</a></li>
<li class="chapter" data-level="5.2" data-path="natural-experiments.html"><a href="natural-experiments.html#difference-in-differences"><i class="fa fa-check"></i><b>5.2</b> Difference-in-differences</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="risk-assessment.html"><a href="risk-assessment.html"><i class="fa fa-check"></i><b>6</b> Risk assessment</a></li>
<li class="chapter" data-level="7" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html"><i class="fa fa-check"></i><b>7</b> Longitudinal cohort study designs</a><ul>
<li class="chapter" data-level="7.1" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#longitudinal-cohort-data"><i class="fa fa-check"></i><b>7.1</b> Longitudinal cohort data</a></li>
<li class="chapter" data-level="7.2" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#coding-a-survival-analysis"><i class="fa fa-check"></i><b>7.2</b> Coding a survival analysis</a></li>
<li class="chapter" data-level="7.3" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#handling-complexity"><i class="fa fa-check"></i><b>7.3</b> Handling complexity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#multi-level-exposure"><i class="fa fa-check"></i><b>7.3.1</b> Multi-level exposure</a></li>
<li class="chapter" data-level="7.3.2" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#recurrent-outcome"><i class="fa fa-check"></i><b>7.3.2</b> Recurrent outcome</a></li>
<li class="chapter" data-level="7.3.3" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#time-varying-coeffificents"><i class="fa fa-check"></i><b>7.3.3</b> Time-varying coeffificents</a></li>
<li class="chapter" data-level="7.3.4" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#using-survey-results"><i class="fa fa-check"></i><b>7.3.4</b> Using survey results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html"><i class="fa fa-check"></i><b>8</b> Some approaches for confounding</a><ul>
<li class="chapter" data-level="8.1" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#inverse-probability-weighting"><i class="fa fa-check"></i><b>8.1</b> Inverse probability weighting</a></li>
<li class="chapter" data-level="8.2" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#propensity-scores"><i class="fa fa-check"></i><b>8.2</b> Propensity scores</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>9</b> Mixed models</a></li>
<li class="chapter" data-level="10" data-path="instrumental-variables.html"><a href="instrumental-variables.html"><i class="fa fa-check"></i><b>10</b> Instrumental variables</a></li>
<li class="chapter" data-level="11" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>11</b> Causal inference</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Epidemiological Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="time-series-case-crossover-study-designs" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Time series / case-crossover study designs</h1>
<div id="reading" class="section level2">
<h2><span class="header-section-number">3.1</span> Reading</h2>
<p>The readings for this chapter are:</p>
<ul>
<li><span class="citation">Vicedo-Cabrera, Sera, and Gasparrini (<a href="#ref-vicedo2019hands" role="doc-biblioref">2019</a>)</span>, with supplemental material available to download by
clicking <a href="http://links.lww.com/EDE/B504" class="uri">http://links.lww.com/EDE/B504</a></li>
<li><span class="citation">Armstrong, Gasparrini, and Tobias (<a href="#ref-armstrong2014conditional" role="doc-biblioref">2014</a>)</span>, with supplemental material available at
<a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-122#Sec13" class="uri">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-14-122#Sec13</a></li>
</ul>
</div>
<div id="time-series-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Time series data</h2>
<p>Example datasets are available as part of the supplemental material for
both of the articles in this chapter’s readings. For <span class="citation">Vicedo-Cabrera, Sera, and Gasparrini (<a href="#ref-vicedo2019hands" role="doc-biblioref">2019</a>)</span>,
the example data are available as the file “lndn_obs.csv”. These data are
saved in a csv format, and so they can be read into R using the
<code>read_csv</code> function from the <code>readr</code> package (part of the tidyverse).
For example, you can use the following code to read in these data,
assuming you have saved them in a “data” subdirectory of your current
working directory:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="time-series-case-crossover-study-designs.html#cb1-1"></a><span class="kw">library</span>(tidyverse) <span class="co"># Loads all the tidyverse packages, including readr</span></span>
<span id="cb1-2"><a href="time-series-case-crossover-study-designs.html#cb1-2"></a>obs &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/lndn_obs.csv&quot;</span>)</span>
<span id="cb1-3"><a href="time-series-case-crossover-study-designs.html#cb1-3"></a>obs</span></code></pre></div>
<pre><code>## # A tibble: 8,279 x 14
##    date        year month   day   doy dow     all all_0_64 all_65_74 all_75_84
##    &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 1990-01-01  1990     1     1     1 Mon     220       38        38        82
##  2 1990-01-02  1990     1     2     2 Tue     257       50        67        87
##  3 1990-01-03  1990     1     3     3 Wed     245       39        59        86
##  4 1990-01-04  1990     1     4     4 Thu     226       41        45        77
##  5 1990-01-05  1990     1     5     5 Fri     236       45        54        85
##  6 1990-01-06  1990     1     6     6 Sat     235       48        48        84
##  7 1990-01-07  1990     1     7     7 Sun     231       38        49        96
##  8 1990-01-08  1990     1     8     8 Mon     235       46        57        76
##  9 1990-01-09  1990     1     9     9 Tue     250       48        54        96
## 10 1990-01-10  1990     1    10    10 Wed     214       44        46        62
## # … with 8,269 more rows, and 4 more variables: all_85plus &lt;dbl&gt;, tmean &lt;dbl&gt;,
## #   tmin &lt;dbl&gt;, tmax &lt;dbl&gt;</code></pre>
<p>This example dataset shows many characteristics that are common for datasets for
time series studies in environmental epidemiology. Time series data are essentially
a sequence of data points repeatedly taken over a certain time interval (e.g. day,
week, month etc). General characteristics of time series data for environmental epidemiology studies are:</p>
<ul>
<li>Observations are given at an aggregated level. For example, instead of
individual observations for each person in London, the <code>obs</code> data give
counts of deaths throughout London. The level of aggregation is often determined
by geopolitical boundaries, for example counties of ZIP codes in the US.</li>
<li>Observations are given at regularly spaced time steps over a period. In the
<code>obs</code> dataset, the time interval is day. Typically, values will be provided
continuously over that time period, with observations for each time interval.
Occasionally, however, the time series data may only be available for
particular seasons (e.g., only warm season dates for an ozone study), or
there may be some missing data on either the exposure or health outcome over
the course of the study period.</li>
<li>Daily observations are given for the health outcome, for the environmental
exposure of interest, and for potential time-varying confounders. In the <code>obs</code>
dataset, the health outcome is mortality (from all causes; sometimes, the health
outcome will focus on a specific cause of mortality or other health outcomes such
as hospitalizations or emergency room visits). Counts are given for everyone in
the city for each day (<code>all</code> column), as well as for specific age categories
(<code>all_0_64</code> for all deaths among those up to 64 years old, and so on). The
exposure of interest in the <code>obs</code> dataset is temperature, and three metrics of
this are included (<code>tmean</code>, <code>tmin</code>, and <code>tmax</code>). Day of the week is one
time-varying factor that could be a confounder, or at least help explain
variation in the outcome (mortality). This is included through the <code>dow</code> variable
in the <code>obs</code> data. Sometimes, you will also see a marker for holidays included
as a potential time-varying confounder, or other exposure variables (temperature
is a potential confounder, for example, when investigating the relationship
between air pollution and mortality risk).</li>
<li>Multiple metrics of an exposure and / or multiple health outcome counts
may be included for each time step. In the <code>obs</code> example, three metrics of
temperature are included (minimum daily temperature, maximum daily temperature,
and mean daily temperature). Several counts of mortality are included, providing
information for specific age categories in the population.</li>
</ul>
<p>When working with time series data, it is helpful to start with some exploratory
data analysis. The following applied exercise will take you through some of the
questions you might want to answer through this type of exploratory analysis. In
general, the <code>lubridate</code> package is an excellent tool for working with date data
in R (although, in the example code above, we mostly used tools from base R).
You may find it worthwhile to explore this package some more. There is a helpful
chapter in <span class="citation">Wickham and Grolemund (<a href="#ref-wickham2016r" role="doc-biblioref">2016</a>)</span>, <a href="https://r4ds.had.co.nz/dates-and-times.html" class="uri">https://r4ds.had.co.nz/dates-and-times.html</a>, as well
as a cheatsheet at
<a href="https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_lubridate.pdf" class="uri">https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_lubridate.pdf</a>. For
visualizations, if you are still learning techniques in R, two books
you may find useful are
<span class="citation">Healy (<a href="#ref-healy2018data" role="doc-biblioref">2018</a>)</span> (available online at <a href="https://socviz.co/" class="uri">https://socviz.co/</a>) and <span class="citation">Chang (<a href="#ref-chang2018r" role="doc-biblioref">2018</a>)</span>
(available online at <a href="http://www.cookbook-r.com/Graphs/" class="uri">http://www.cookbook-r.com/Graphs/</a>).</p>
<p><em>Applied: Exploring time series data</em></p>
<p>Read the example time series data in R and explore it to answer the following
questions:</p>
<ol style="list-style-type: decimal">
<li>What is the study period for the example <code>obs</code> dataset? (i.e., what
dates / years are covered by the time series data?)</li>
<li>Are there any missing dates within this time period?</li>
<li>Are there seasonal trends in the exposure? In the outcome?</li>
<li>Are there long-term trends in the exposure? In the outcome?</li>
<li>Is the outcome associated with day of week? Is the exposure associated
with day of week?</li>
</ol>
<p>Based on your exploratory analysis in this section, talk about the potential
for confounding when these data are analyzed to estimate the association between
daily temperature and city-wide mortality. Is confounding by seasonal trends
a concern? How about confounding by long-term trends in exposure and mortality?
How about confounding by day of week?</p>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>What is the study period for the example <code>obs</code> dataset? (i.e., what
dates / years are covered by the time series data?)</strong></li>
</ol>
<p>In the <code>obs</code> dataset, the date of each observation is included in a column called
<code>date</code>. The data type of this column is “Date”—you can check this by using
the <code>class</code> function from base R:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="time-series-case-crossover-study-designs.html#cb3-1"></a><span class="kw">class</span>(obs<span class="op">$</span>date)</span></code></pre></div>
<pre><code>## [1] &quot;Date&quot;</code></pre>
<p>Since this column has a “Date” data type, you can run some mathematical function
calls on it. For example, you can use the <code>min</code> function from base R to get the
earliest date in the dataset and the <code>max</code> function to get the latest.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="time-series-case-crossover-study-designs.html#cb5-1"></a><span class="kw">min</span>(obs<span class="op">$</span>date)</span></code></pre></div>
<pre><code>## [1] &quot;1990-01-01&quot;</code></pre>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="time-series-case-crossover-study-designs.html#cb7-1"></a><span class="kw">max</span>(obs<span class="op">$</span>date)</span></code></pre></div>
<pre><code>## [1] &quot;2012-08-31&quot;</code></pre>
<p>You can also run the <code>range</code> function to get both the earliest and latest dates
with a single call:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="time-series-case-crossover-study-designs.html#cb9-1"></a><span class="kw">range</span>(obs<span class="op">$</span>date)</span></code></pre></div>
<pre><code>## [1] &quot;1990-01-01&quot; &quot;2012-08-31&quot;</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><strong>Are there any missing dates within this time period?</strong></li>
</ol>
<p>There are a few things you should check to answer this question. First
(and easiest), you can check to see if there are any <code>NA</code> values within
any of the observations in the dataset. The <code>summary</code> function will provide
a summary of the values in each column of the dataset, including the count
of missing values (NAs) if there are any:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="time-series-case-crossover-study-designs.html#cb11-1"></a><span class="kw">summary</span>(obs)</span></code></pre></div>
<pre><code>##       date                 year          month             day       
##  Min.   :1990-01-01   Min.   :1990   Min.   : 1.000   Min.   : 1.00  
##  1st Qu.:1995-09-01   1st Qu.:1995   1st Qu.: 3.000   1st Qu.: 8.00  
##  Median :2001-05-02   Median :2001   Median : 6.000   Median :16.00  
##  Mean   :2001-05-02   Mean   :2001   Mean   : 6.464   Mean   :15.73  
##  3rd Qu.:2006-12-31   3rd Qu.:2006   3rd Qu.: 9.000   3rd Qu.:23.00  
##  Max.   :2012-08-31   Max.   :2012   Max.   :12.000   Max.   :31.00  
##       doy            dow                 all           all_0_64   
##  Min.   :  1.0   Length:8279        Min.   : 81.0   Min.   : 9.0  
##  1st Qu.: 90.5   Class :character   1st Qu.:138.0   1st Qu.:27.0  
##  Median :180.0   Mode  :character   Median :157.0   Median :32.0  
##  Mean   :181.3                      Mean   :160.2   Mean   :32.4  
##  3rd Qu.:272.0                      3rd Qu.:178.0   3rd Qu.:37.0  
##  Max.   :366.0                      Max.   :363.0   Max.   :64.0  
##    all_65_74       all_75_84        all_85plus         tmean       
##  Min.   : 6.00   Min.   : 17.00   Min.   : 17.00   Min.   :-5.503  
##  1st Qu.:23.00   1st Qu.: 41.00   1st Qu.: 39.00   1st Qu.: 7.470  
##  Median :29.00   Median : 49.00   Median : 45.00   Median :11.465  
##  Mean   :30.45   Mean   : 50.65   Mean   : 46.68   Mean   :11.614  
##  3rd Qu.:37.00   3rd Qu.: 58.00   3rd Qu.: 53.00   3rd Qu.:15.931  
##  Max.   :70.00   Max.   :138.00   Max.   :128.00   Max.   :29.143  
##       tmin             tmax       
##  Min.   :-8.940   Min.   :-3.785  
##  1st Qu.: 3.674   1st Qu.:10.300  
##  Median : 7.638   Median :14.782  
##  Mean   : 7.468   Mean   :15.058  
##  3rd Qu.:11.438   3rd Qu.:19.830  
##  Max.   :20.438   Max.   :37.087</code></pre>
<p>Based on this analysis, all observations are complete for all dates included
in the dataset.</p>
<p>However, this does not guarantee that every date between the start date and
end date of the study period are included in the recorded data. Sometimes,
some dates might not get recorded at all in the dataset, and the <code>summary</code>
function won’t help you determine when this is the case.</p>
<p>There are a few alternative explorations you can do. First, you can check
the number of days between the start and end date of the study period, and
then see if the number of observations in the dataset is the same:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="time-series-case-crossover-study-designs.html#cb13-1"></a><span class="co"># Calculate number of days in study period</span></span>
<span id="cb13-2"><a href="time-series-case-crossover-study-designs.html#cb13-2"></a>obs <span class="op">%&gt;%</span><span class="st">            </span><span class="co"># Using piping (%&gt;%) throughout to keep code clear</span></span>
<span id="cb13-3"><a href="time-series-case-crossover-study-designs.html#cb13-3"></a><span class="st">  </span><span class="kw">pull</span>(date) <span class="op">%&gt;%</span><span class="st">   </span><span class="co"># Extract the `date` column as a vector</span></span>
<span id="cb13-4"><a href="time-series-case-crossover-study-designs.html#cb13-4"></a><span class="st">  </span><span class="kw">range</span>() <span class="op">%&gt;%</span><span class="st">      </span><span class="co"># Take the range of dates (earliest and latest)</span></span>
<span id="cb13-5"><a href="time-series-case-crossover-study-designs.html#cb13-5"></a><span class="st">  </span><span class="kw">diff</span>()           <span class="co"># Calculate time difference from start to finish of study </span></span></code></pre></div>
<pre><code>## Time difference of 8278 days</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="time-series-case-crossover-study-designs.html#cb15-1"></a><span class="co"># Get number of observations in dataset---should be 1 more than time difference</span></span>
<span id="cb15-2"><a href="time-series-case-crossover-study-designs.html#cb15-2"></a>obs <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb15-3"><a href="time-series-case-crossover-study-designs.html#cb15-3"></a><span class="st">  </span><span class="kw">nrow</span>()</span></code></pre></div>
<pre><code>## [1] 8279</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><strong>Are there seasonal trends in the exposure? In the outcome?</strong></li>
</ol>
<p>You can use a simple plot to visualize patterns over time in both the exposure
and the outcome. For example, the following code plots a dot for each daily
temperature observation over the study period. The points are set to a smaller
size (<code>size = 0.5</code>) and plotted with some transparency (<code>alpha = 0.5</code>) since
there are so many observations.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="time-series-case-crossover-study-designs.html#cb17-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> date, <span class="dt">y =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb17-2"><a href="time-series-case-crossover-study-designs.html#cb17-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-8-1.png" width="672" />
There is clear evidence here of a strong seasonal trend in mean temperature,
with values typically lowest in the winter and highest in the summer.</p>
<p>You can plot the outcome variable in the same way:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="time-series-case-crossover-study-designs.html#cb18-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> date, <span class="dt">y =</span> all)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb18-2"><a href="time-series-case-crossover-study-designs.html#cb18-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Again, there are seasonal trends, although in this case they are inversed.
Mortality tends to be highest in the winter and lowest in the summer. Further, the
seasonal pattern is not equally strong in all years—some years it has a much
higher winter peak, probably in conjunction with severe influenza seasons.</p>
<p>Another way to look for seasonal trends is with a heatmap-style visualization,
with day of year along the x-axis and year along the y-axis. This allows you
to see patterns that repeat around the same time of the year each year (and
also unusual deviations from normal seaonsal patterns).</p>
<p>For example, here’s a plot showing temperature in each year, where the
observations are aligned on the x-axis by time in year. We’ve reversed
the y-axis so that the earliest years in the study period start at the top
of the visual, then later study years come later—this is a personal style,
and it would be no problem to leave the y-axis as-is. We’ve used the
<code>viridis</code> color scale for the fill, since that has a number of features
that make it preferable to the default R color scale, including that it
is perceptible for most types of color blindness and be printed out in grayscale
and still be correctly interpreted.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="time-series-case-crossover-study-designs.html#cb19-1"></a><span class="kw">library</span>(viridis)</span></code></pre></div>
<pre><code>## Warning: package &#39;viridis&#39; was built under R version 4.0.2</code></pre>
<pre><code>## Warning: package &#39;viridisLite&#39; was built under R version 4.0.1</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="time-series-case-crossover-study-designs.html#cb22-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> doy, <span class="dt">y =</span> year, <span class="dt">fill =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb22-2"><a href="time-series-case-crossover-study-designs.html#cb22-2"></a><span class="st">  </span><span class="kw">geom_tile</span>() <span class="op">+</span></span>
<span id="cb22-3"><a href="time-series-case-crossover-study-designs.html#cb22-3"></a><span class="st">  </span><span class="kw">scale_y_reverse</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb22-4"><a href="time-series-case-crossover-study-designs.html#cb22-4"></a><span class="st">  </span><span class="kw">scale_fill_viridis</span>()</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>From this visualization, you can see that temperatures tend to be higher in the
summer months and lower in the winter months. “Spells” of extreme heat or cold
are visible—where extreme temperatures tend to persist over a period, rather
than randomly fluctuating within a season. You can also see unusual events, like
the extreme heat wave in the summer of 2003, indicated with the brightest
yellow in the plot.</p>
<p>We created the same style of plot for the health outcome. In this case, we
focused on mortality among the oldest age group, as temperature sensitivity
tends to increase with age, so this might be where the strongest patterns are
evident.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="time-series-case-crossover-study-designs.html#cb23-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> doy, <span class="dt">y =</span> year, <span class="dt">fill =</span> all_85plus)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb23-2"><a href="time-series-case-crossover-study-designs.html#cb23-2"></a><span class="st">  </span><span class="kw">geom_tile</span>() <span class="op">+</span></span>
<span id="cb23-3"><a href="time-series-case-crossover-study-designs.html#cb23-3"></a><span class="st">  </span><span class="kw">scale_y_reverse</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb23-4"><a href="time-series-case-crossover-study-designs.html#cb23-4"></a><span class="st">  </span><span class="kw">scale_fill_viridis</span>()</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>For mortality, there tends to be an increase in the winter compared to the summer.
Some winters have stretches with particularly high mortality—these are likely
a result of seasons with strong influenza outbreaks. You can also see on this
plot the impact of the 2003 heat wave on mortality among this oldest age group.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Are there long-term trends in the exposure? In the outcome?</strong></li>
</ol>
<p>Some of the plots we created in the last section help in exploring this
question. For example, the following plot shows a clear pattern of decreasing
daily mortality counts, on average, over the course of the study period:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="time-series-case-crossover-study-designs.html#cb24-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> date, <span class="dt">y =</span> all)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb24-2"><a href="time-series-case-crossover-study-designs.html#cb24-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>It can be helpful to add a smooth line to help detect these longer-term
patterns, which you can do with <code>geom_smooth</code>:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="time-series-case-crossover-study-designs.html#cb25-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> date, <span class="dt">y =</span> all)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb25-2"><a href="time-series-case-crossover-study-designs.html#cb25-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb25-3"><a href="time-series-case-crossover-study-designs.html#cb25-3"></a><span class="st">  </span><span class="kw">geom_smooth</span>()</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>You could also take the median mortality count across each year in the
study period, although you should take out any years without a full year’s
worth of data before you do this, since there are seasonal trends in the
outcome:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="time-series-case-crossover-study-designs.html#cb26-1"></a>obs <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb26-2"><a href="time-series-case-crossover-study-designs.html#cb26-2"></a><span class="st">  </span><span class="kw">group_by</span>(year) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb26-3"><a href="time-series-case-crossover-study-designs.html#cb26-3"></a><span class="st">  </span><span class="kw">filter</span>(year <span class="op">!=</span><span class="st"> </span><span class="dv">2012</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># Take out the last year</span></span>
<span id="cb26-4"><a href="time-series-case-crossover-study-designs.html#cb26-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">median_mort =</span> <span class="kw">median</span>(all)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb26-5"><a href="time-series-case-crossover-study-designs.html#cb26-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year, <span class="dt">y =</span> median_mort)) <span class="op">+</span></span>
<span id="cb26-6"><a href="time-series-case-crossover-study-designs.html#cb26-6"></a><span class="st">  </span><span class="kw">geom_line</span>()</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Is the outcome associated with day of week? Is the exposure associated
with day of week?</strong></li>
</ol>
<p>The data already has day of week as a column in the data (<code>dow</code>). However,
this is in a character data type, so it doesn’t have the order of weekdays
encoded (e.g., Monday comes before Tuesday). This makes it hard to look for
patterns related to things like weekend / weekday.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="time-series-case-crossover-study-designs.html#cb28-1"></a><span class="kw">class</span>(obs<span class="op">$</span>dow)</span></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<p>We could convert this to a factor and encode the weekday order when we do
it, but it’s even easier to just recreate the column from the <code>date</code> column.
We used the <code>wday</code> function from the <code>lubridate</code> package to do this—it extracts
weekday as a factor, with the order of weekdays encoded (using a special
“ordered” factor type):</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="time-series-case-crossover-study-designs.html#cb30-1"></a><span class="kw">library</span>(lubridate)</span></code></pre></div>
<pre><code>## Warning: package &#39;lubridate&#39; was built under R version 4.0.2</code></pre>
<pre><code>## 
## Attaching package: &#39;lubridate&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     date, intersect, setdiff, union</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="time-series-case-crossover-study-designs.html#cb34-1"></a>obs &lt;-<span class="st"> </span>obs <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb34-2"><a href="time-series-case-crossover-study-designs.html#cb34-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dow =</span> <span class="kw">wday</span>(date, <span class="dt">label =</span> <span class="ot">TRUE</span>))</span>
<span id="cb34-3"><a href="time-series-case-crossover-study-designs.html#cb34-3"></a></span>
<span id="cb34-4"><a href="time-series-case-crossover-study-designs.html#cb34-4"></a><span class="kw">class</span>(obs<span class="op">$</span>dow)</span></code></pre></div>
<pre><code>## [1] &quot;ordered&quot; &quot;factor&quot;</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="time-series-case-crossover-study-designs.html#cb36-1"></a><span class="kw">levels</span>(obs<span class="op">$</span>dow)</span></code></pre></div>
<pre><code>## [1] &quot;Sun&quot; &quot;Mon&quot; &quot;Tue&quot; &quot;Wed&quot; &quot;Thu&quot; &quot;Fri&quot; &quot;Sat&quot;</code></pre>
<p>We looked at the mean, median, and 25th and 75th quantiles of the mortality
counts by day of week:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="time-series-case-crossover-study-designs.html#cb38-1"></a>obs <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb38-2"><a href="time-series-case-crossover-study-designs.html#cb38-2"></a><span class="st">  </span><span class="kw">group_by</span>(dow) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb38-3"><a href="time-series-case-crossover-study-designs.html#cb38-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="kw">mean</span>(all), </span>
<span id="cb38-4"><a href="time-series-case-crossover-study-designs.html#cb38-4"></a>            <span class="kw">median</span>(all), </span>
<span id="cb38-5"><a href="time-series-case-crossover-study-designs.html#cb38-5"></a>            <span class="kw">quantile</span>(all, <span class="fl">0.25</span>), </span>
<span id="cb38-6"><a href="time-series-case-crossover-study-designs.html#cb38-6"></a>            <span class="kw">quantile</span>(all, <span class="fl">0.75</span>))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 7 x 5
##   dow   `mean(all)` `median(all)` `quantile(all, 0.25)` `quantile(all, 0.75)`
##   &lt;ord&gt;       &lt;dbl&gt;         &lt;dbl&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;
## 1 Sun          156.           154                  136                    173
## 2 Mon          161.           159                  138                    179
## 3 Tue          161.           158                  139                    179
## 4 Wed          160.           157                  138.                   179
## 5 Thu          161.           158                  139                    179
## 6 Fri          162.           159                  141                    179
## 7 Sat          159.           156                  137                    178</code></pre>
<p>Mortality tends to be a bit higher on weekdays than weekends, but it’s not
a dramatic difference.</p>
<p>We did the same check for temperature:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="time-series-case-crossover-study-designs.html#cb41-1"></a>obs <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb41-2"><a href="time-series-case-crossover-study-designs.html#cb41-2"></a><span class="st">  </span><span class="kw">group_by</span>(dow) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb41-3"><a href="time-series-case-crossover-study-designs.html#cb41-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="kw">mean</span>(tmean), </span>
<span id="cb41-4"><a href="time-series-case-crossover-study-designs.html#cb41-4"></a>            <span class="kw">median</span>(tmean), </span>
<span id="cb41-5"><a href="time-series-case-crossover-study-designs.html#cb41-5"></a>            <span class="kw">quantile</span>(tmean, <span class="fl">0.25</span>), </span>
<span id="cb41-6"><a href="time-series-case-crossover-study-designs.html#cb41-6"></a>            <span class="kw">quantile</span>(tmean, <span class="fl">0.75</span>))</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 7 x 5
##   dow   `mean(tmean)` `median(tmean)` `quantile(tmean, 0.2… `quantile(tmean, 0.…
##   &lt;ord&gt;         &lt;dbl&gt;           &lt;dbl&gt;                 &lt;dbl&gt;                &lt;dbl&gt;
## 1 Sun            11.6            11.3                  7.48                 15.9
## 2 Mon            11.6            11.4                  7.33                 15.8
## 3 Tue            11.5            11.4                  7.48                 15.9
## 4 Wed            11.7            11.7                  7.64                 16.0
## 5 Thu            11.6            11.5                  7.57                 16.0
## 6 Fri            11.6            11.6                  7.41                 15.8
## 7 Sat            11.6            11.5                  7.53                 15.9</code></pre>
<p>In this case, there does not seem to be much of a pattern by weekday.</p>
<p>You can also visualize the association using boxplots:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="time-series-case-crossover-study-designs.html#cb44-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">wday</span>(date, <span class="dt">label =</span> <span class="ot">TRUE</span>), <span class="dt">y =</span> all)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb44-2"><a href="time-series-case-crossover-study-designs.html#cb44-2"></a><span class="st">  </span><span class="kw">geom_boxplot</span>()</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>You can also try violin plots—these show the full distribution better than
boxplots, which only show quantiles.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="time-series-case-crossover-study-designs.html#cb45-1"></a><span class="kw">ggplot</span>(obs, <span class="kw">aes</span>(<span class="dt">x =</span> dow, <span class="dt">y =</span> all)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb45-2"><a href="time-series-case-crossover-study-designs.html#cb45-2"></a><span class="st">  </span><span class="kw">geom_violin</span>(<span class="dt">draw_quantiles =</span> <span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>))</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="fitting-models" class="section level2">
<h2><span class="header-section-number">3.3</span> Fitting models</h2>
<p>One of the readings for this week, <span class="citation">Vicedo-Cabrera, Sera, and Gasparrini (<a href="#ref-vicedo2019hands" role="doc-biblioref">2019</a>)</span>, includes a section
on fitting exposure-response functions to describe the association between
daily mean temperature and mortality risk. This article includes example
code in its supplemental material, with code for fitting the model to
these time series data in the file named “01EstimationERassociation.r”.
The model may at first seem complex, but it is made up of a number of
fairly straightforward pieces (although some may initially seem complex):</p>
<ul>
<li>The model framework is a <em>generalized linear model (GLM)</em></li>
<li>This GLM is fit assuming an <em>error distribution</em> and a <em>link function</em>
appropriate for count data</li>
<li>The GLM is fit assuming an <em>error distribution</em> that is also appropriate for
data that may be <em>overdispersed</em></li>
<li>The model includes control for day of the week by including a <em>categorical
variable</em></li>
<li>The model includes control for long-term and seasonal trends by including
a <em>spline</em> (in this case, a <em>natural cubic spline</em>) for the day in the study</li>
<li>The model fits a flexible, non-linear association between temperature
and mortality risk also using a spline</li>
<li>The model fits a flexible non-linear association between temperature on
a series of preceeding days and current day and mortality risk on the
current day using a <em>distributed lag approach</em></li>
<li>The model jointly describes both of the two previous non-linear associations
by fitting these two elements through one construct in the GLM, a
<em>cross-basis term</em></li>
</ul>
<p>In this section, we will work through the elements, building up the code to
get to the full model that is fit in <span class="citation">Vicedo-Cabrera, Sera, and Gasparrini (<a href="#ref-vicedo2019hands" role="doc-biblioref">2019</a>)</span>.</p>
<p><em>Fitting a GLM to time series data</em></p>
<p>The GLM framework unites a number of types of regression models you may have
previously worked with. One basic regression model that can be fit within this
framework is a linear regression model. However, the framework also allows you
to also fit, among others, logistic regression models (useful when the outcome
variable can only take one of two values, e.g., success / failure or alive /
dead), Poisson regression models (useful when the outcome variable is a count or
rate).</p>
<p>This generalized framework brings some unity to these different types of
regression models. From a practical standpoint, it has allowed software
developers to easily provide a common interface to fit these types of models.
In R, the common function call to fit GLMs is <code>glm</code>.</p>
<p>Within the GLM framework, the elements that separate different regression models
include the link function and the error distribution. The error distribution
encodes the assumption you are enforcing about how the errors after fitting the
model are distributed. If the outcome data are normally distributed (a.k.a.,
follow a Gaussian distribution), after accounting for variance explained in the
outcome by any of the model covariates, then a linear regression model may be
appropriate. For count data—like numbers of deaths a day—this is unlikely,
unless the average daily mortality count is very high (count data tend to
come closer to a normal distribution the further their average gets from
0). For binary data—like whether each person in a study population died on
a given day or not—normally distributed errors are also unlikely. Instead,
in these two cases, it is typically more appropriate to fit GLMs with
Poisson and binomial “families”, respectively, where the family designation
includes an appropriate specification for the variance when fitting the model
based on these outcome types.</p>
<p>The other element that distinguishes different types of regression within
the GLM framework is the link function. The link function applies a transformation
on the combination of independent variables in the regression equation
when fitting the model. With normally distributed data, an <em>identity link</em>
is often appropriate—with this link, the combination of independent variables
remain unchanged (i.e., keep their initial “identity”). With count data, a
<em>log link</em> is often more appropriate, while with binomial data, a <em>logit link</em>
is often used.</p>
<p>Finally, data will often not perfectly adhere to assumptions. For example, the
Poisson family of GLMs assumes that variance follows a Poisson distribution
(The probability mass function for Poisson distribution <span class="math inline">\(X \sim {\sf Poisson}(\mu)\)</span> is denoted by <span class="math inline">\(f(k;\mu)=Pr[X=k]= \displaystyle \frac{\mu^{k}e^{-\mu}}{k!}\)</span>, where
<span class="math inline">\(k\)</span> is the number of occurences, and <span class="math inline">\(\mu\)</span> is equal to the expected number of
cases). With this distribution, the variance is equal to the mean (<span class="math inline">\(\mu=E(X)=Var(X)\)</span>). With real-life data, this assumption is often not valid, and in many cases the variance in real life count data is larger than the mean. This can be accounted for when fitting a GLM by setting an error distribution that does not require the variance to equal the mean—instead, both a mean value and something like a
variance are estimated from the data, assuming an overdispersion parameter <span class="math inline">\(\phi\)</span>
so that <span class="math inline">\(Var(X)=\phi E(X)\)</span>. In environmental epidemiology, time series
are often fit to allow for this overdispersion. This is because if the data are overdispersed but the model does not account for this, the standard errors on the
estimates of the model parameters may be artificially small. If the data are not overdispersed (<span class="math inline">\(\phi=1\)</span>), the model will identify this when being fit to the data,
so it is typically better to prefer to allow for overdispersion in the model
(if the size of the data were small, you may want to be parsimonious and avoid
unneeded complexity in the model, but this is typically not the case with time
series data).</p>
<p>In the next section, you will work through the steps of developing a GLM to fit
the example dataset <code>obs</code>. For now, you will only fit a linear association
between mean daily temperature and mortality risk, eventually including control
for day of week. In later work, especially the next chapter, we will build up
other components of the model, including control for the potential confounders
of long-term and seasonal patterns, as well as advancing the model to fit
non-linear associations, distributed by time, through splines, a distributed lag
approach, and a cross-basis term.</p>
<p><em>Applied: Fitting a GLM to time series data</em></p>
<p>In R, the function call used to fit GLMs is <code>glm</code>. Most of you have likely
covered GLMs, and ideally this function call, in previous courses. If you are
unfamiliar with its basic use, you will want to refresh yourself on this
topic. [Add some online resources that go over basics of GLMs in R.]</p>
<ol style="list-style-type: decimal">
<li>Fit a GLM to estimate the association between mean daily temperature (as the
independent variable) and daily mortality count (as the dependent variable),
first fitting a linear regression. (Since the mortality data are counts, we will
want to shift to a different type of regression within the GLM framework, but
this step allows you to develop a simple <code>glm</code> call, and to remember where to
include the data and the independent and dependent variables within this
function call.)</li>
<li>Change your function call to fit a regression model in the Poisson family.</li>
<li>Change your function call to allow for overdispersion in the outcome data
(daily mortality count). How does the estimated coefficient for temperature
change between the model fit for #2 and this model? Check both the central
estimate and its estimated standard error.</li>
<li>Change your function call to include control for day of week.</li>
</ol>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>Fit a GLM to estimate the association between mean daily temperature (as the
independent variable) and daily mortality count (as the dependent variable),
first fitting a linear regression.</strong></li>
</ol>
<p>This is the model you are fitting:</p>
<p><span class="math inline">\(Y_{t}=\beta_{0}+\beta_{1}X1_{t}+\epsilon\)</span></p>
<p>where <span class="math inline">\(Y_{t}\)</span> is the mortality count on day <span class="math inline">\(t\)</span>, <span class="math inline">\(X1_{t}\)</span> is the mean temperature
for day <span class="math inline">\(t\)</span> and <span class="math inline">\(\epsilon\)</span> is the error term. Since this is a linear model we are
assuming a Gaussian error distribution <span class="math inline">\(\epsilon \sim {\sf N}(0, \sigma^{2})\)</span>,
where <span class="math inline">\(\sigma^{2}\)</span> is the variance not explained by the covariates (here just
temperature).</p>
<p>To do this, you will use the <code>glm</code> call. If you would like to save model fit
results to use later, you assign the output a name as an R object
(<code>mod_linear_reg</code> in the example code). If your study data are in a dataframe,
you can specify these data in the <code>glm</code> call with the <code>data</code> parameter.
Once you do this, you can use column names directly in the model formula.
In the model formula, the dependent variable is specified first (<code>all</code>, the
column for daily mortality counts for all ages, in this example), followed
by a tilde (<code>~</code>), followed by all independent variables (only <code>tmean</code> in this
example). If multiple independent variables are included, they are joined using
<code>+</code>—we’ll see an example when we start adding control for confounders later.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="time-series-case-crossover-study-designs.html#cb46-1"></a>mod_linear_reg &lt;-<span class="st"> </span><span class="kw">glm</span>(all <span class="op">~</span><span class="st"> </span>tmean, <span class="dt">data =</span> obs)</span></code></pre></div>
<p>Once you have fit a model and assigned it to an R object, you can explore it
and use resulting values. First, the print method for a regression model
gives some summary information. This method is automatically called if you
enter the model object’s name at the console:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="time-series-case-crossover-study-designs.html#cb47-1"></a>mod_linear_reg</span></code></pre></div>
<pre><code>## 
## Call:  glm(formula = all ~ tmean, data = obs)
## 
## Coefficients:
## (Intercept)        tmean  
##     187.647       -2.366  
## 
## Degrees of Freedom: 8278 Total (i.e. Null);  8277 Residual
## Null Deviance:       8161000 
## Residual Deviance: 6766000   AIC: 79020</code></pre>
<p>More information is printed if you run the <code>summary</code> method on the model
object:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="time-series-case-crossover-study-designs.html#cb49-1"></a><span class="kw">summary</span>(mod_linear_reg)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = all ~ tmean, data = obs)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -77.301  -20.365   -1.605   17.502  169.280  
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 187.64658    0.73557  255.10   &lt;2e-16 ***
## tmean        -2.36555    0.05726  -41.31   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 817.4629)
## 
##     Null deviance: 8161196  on 8278  degrees of freedom
## Residual deviance: 6766140  on 8277  degrees of freedom
## AIC: 79019
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>Make sure you are familiar with the information provided from the model object,
as well as how to interpret values like the coefficient estimates and their
standard errors and p-values. These basic elements should have been covered in
previous coursework (even if a different programming language was used to fit
the model), and so we will not be covering them in great depth here, but instead
focusing on some of the more advanced elements of how regression models are
commonly fit to data from time series and case-crossover study designs in
environmental epidemiology. For a refresher on the basics of fitting
statistical models in R, you may want to check out Chapters 22 through 24 of
<span class="citation">Wickham and Grolemund (<a href="#ref-wickham2016r" role="doc-biblioref">2016</a>)</span>, a book that is available online.</p>
<p>Finally, there are some newer tools for extracting information from model fit
objects. The <code>broom</code> package extracts different elements from these objects
and returns them in a “tidy” data format, which makes it much easier to use
the output further in analysis with functions from the “tidyverse” suite of
R packages. These tools are very popular and powerful, and so the <code>broom</code> tools
can be very useful in working with output from regression modeling in R.</p>
<p>The <code>broom</code> package includes three main functions for extracting data from
regression model objects. First, the <code>glance</code> function returns overall data
about the model fit, including the AIC and BIC:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="time-series-case-crossover-study-designs.html#cb51-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb51-2"><a href="time-series-case-crossover-study-designs.html#cb51-2"></a><span class="kw">glance</span>(mod_linear_reg)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 8
##   null.deviance df.null  logLik    AIC    BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1      8161196.    8278 -39507. 79019. 79041. 6766140.        8277  8279</code></pre>
<p>The <code>tidy</code> function returns data at the level of the model coefficients,
including the estimate for each model parameter, its standard error, test
statistic, and p-value.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="time-series-case-crossover-study-designs.html#cb53-1"></a><span class="kw">tidy</span>(mod_linear_reg)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)   188.      0.736      255.        0
## 2 tmean          -2.37    0.0573     -41.3       0</code></pre>
<p>Finally, the <code>augment</code> function returns data at the level of the original
observations, including the fitted value for each observation, the residual
between the fitted and true value, and some measures of influence on the model
fit.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="time-series-case-crossover-study-designs.html#cb55-1"></a><span class="kw">augment</span>(mod_linear_reg)</span></code></pre></div>
<pre><code>## # A tibble: 8,279 x 8
##      all tmean .fitted .resid .std.resid     .hat .sigma  .cooksd
##    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;
##  1   220  3.91    178.   41.6       1.46 0.000359   28.6 0.000380
##  2   257  5.55    175.   82.5       2.89 0.000268   28.6 0.00112 
##  3   245  4.39    177.   67.7       2.37 0.000330   28.6 0.000928
##  4   226  5.43    175.   51.2       1.79 0.000274   28.6 0.000440
##  5   236  6.87    171.   64.6       2.26 0.000211   28.6 0.000539
##  6   235  9.23    166.   69.2       2.42 0.000144   28.6 0.000420
##  7   231  6.69    172.   59.2       2.07 0.000218   28.6 0.000467
##  8   235  7.96    169.   66.2       2.31 0.000174   28.6 0.000467
##  9   250  7.27    170.   79.5       2.78 0.000197   28.6 0.000761
## 10   214  9.51    165.   48.9       1.71 0.000139   28.6 0.000202
## # … with 8,269 more rows</code></pre>
<p>One way you can use <code>augment</code> is to graph the fitted values for each observation
after fitting the model:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="time-series-case-crossover-study-designs.html#cb57-1"></a>mod_linear_reg <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb57-2"><a href="time-series-case-crossover-study-designs.html#cb57-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb57-3"><a href="time-series-case-crossover-study-designs.html#cb57-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb57-4"><a href="time-series-case-crossover-study-designs.html#cb57-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> all), <span class="dt">alpha =</span> <span class="fl">0.4</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb57-5"><a href="time-series-case-crossover-study-designs.html#cb57-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .fitted), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb57-6"><a href="time-series-case-crossover-study-designs.html#cb57-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Mean daily temperature&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Log(Expected mortality count)&quot;</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>For more on the <code>broom</code> package, including some excellent examples of how it
can be used to streamline complex regression analyses, see <span class="citation">Robinson (<a href="#ref-robinson2014broom" role="doc-biblioref">2014</a>)</span>.
There is also a nice example of how it can be used in one of the chapters of
<span class="citation">Wickham and Grolemund (<a href="#ref-wickham2016r" role="doc-biblioref">2016</a>)</span>, available online at <a href="https://r4ds.had.co.nz/many-models.html" class="uri">https://r4ds.had.co.nz/many-models.html</a>.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Change your function call to fit a regression model in the Poisson family.</strong></li>
</ol>
<p>A linear regression is often not appropriate when fitting a model where the
outcome variable provides counts, as with the example data. A Poisson regression
is often preferred.</p>
<p>For a count distribution were <span class="math inline">\(Y \sim {\sf Poisson(\mu)}\)</span> we typically fit a model
such as</p>
<p><span class="math inline">\(g(Y)=\beta_{0}+\beta_{1}X1\)</span>, where <span class="math inline">\(g()\)</span> represents the link function, in this
case a log function so that <span class="math inline">\(log(Y)=\beta_{0}+\beta_{1}X1\)</span>. We can also express
this as <span class="math inline">\(Y=exp(\beta_{0}+\beta_{1}X1)\)</span>.</p>
<p>In the <code>glm</code> call, you can specify this with the <code>family</code>
parameter, for which “poisson” is one choice.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="time-series-case-crossover-study-designs.html#cb58-1"></a>mod_pois_reg &lt;-<span class="st"> </span><span class="kw">glm</span>(all <span class="op">~</span><span class="st"> </span>tmean, <span class="dt">data =</span> obs, <span class="dt">family =</span> <span class="st">&quot;poisson&quot;</span>)</span></code></pre></div>
<p>One thing to keep in mind with this change is that the model now uses a
non-identity link between the combination of independent variable(s) and the
dependent variable. You will need to keep this in mind when you interpret
the estimates of the regression coefficients. While the coefficient estimate
for <code>tmean</code> from the linear regression could be interpreted as the expected
increase in mortality counts for a one-unit (i.e., one degree Celsius) increase
in temperature, now the estimated coefficient should be interpreted as the
expected increase in the natural log-transform of mortality count for a one-unit
increase in temperature.</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="time-series-case-crossover-study-designs.html#cb59-1"></a><span class="kw">summary</span>(mod_pois_reg)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = all ~ tmean, family = &quot;poisson&quot;, data = obs)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.5945  -1.6365  -0.1167   1.3652  12.2221  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  5.2445409  0.0019704 2661.67   &lt;2e-16 ***
## tmean       -0.0147728  0.0001583  -93.29   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 49297  on 8278  degrees of freedom
## Residual deviance: 40587  on 8277  degrees of freedom
## AIC: 97690
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>You can see this even more clearly if you take a look at the association between
temperature for each observation and the expected mortality count fit by the
model. First, if you look at the fitted values without transforming, they
will still be in a state where mortality count is log-transformed. You can
see by looking at the range of the y-scale that these values are for the log
of expected mortality, rather than expected mortality, and that the fitted
association is linear:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="time-series-case-crossover-study-designs.html#cb61-1"></a>mod_pois_reg <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb61-2"><a href="time-series-case-crossover-study-designs.html#cb61-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb61-3"><a href="time-series-case-crossover-study-designs.html#cb61-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb61-4"><a href="time-series-case-crossover-study-designs.html#cb61-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">log</span>(all)), <span class="dt">alpha =</span> <span class="fl">0.4</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb61-5"><a href="time-series-case-crossover-study-designs.html#cb61-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .fitted), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb61-6"><a href="time-series-case-crossover-study-designs.html#cb61-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Mean daily temperature&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Log(Expected mortality count)&quot;</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>You can use exponentiation to transform the fitted values back to just be the
expected mortality count based on the model fit. Once you make this
transformation, you can see how the link in the Poisson family specification
enforced a curved relationship between mean daily temperature and the
untransformed expected mortality count.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="time-series-case-crossover-study-designs.html#cb62-1"></a>mod_pois_reg <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb62-2"><a href="time-series-case-crossover-study-designs.html#cb62-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb62-3"><a href="time-series-case-crossover-study-designs.html#cb62-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb62-4"><a href="time-series-case-crossover-study-designs.html#cb62-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> all), <span class="dt">alpha =</span> <span class="fl">0.4</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb62-5"><a href="time-series-case-crossover-study-designs.html#cb62-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">exp</span>(.fitted)), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb62-6"><a href="time-series-case-crossover-study-designs.html#cb62-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Mean daily temperature&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Expected mortality count&quot;</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Change your function call to allow for overdispersion in the outcome data
(daily mortality count). How does the estimated coefficient for temperature
change between the model fit for #2 and this model? Check both the central
estimate and its estimated standard error.</strong></li>
</ol>
<p>In the R <code>glm</code> call, there is a family that is similar to Poisson (including
using a log link), but that allows for overdispersion. You can specify it
with the “quasipoisson” choice for the <code>family</code> parameter in the <code>glm</code> call:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="time-series-case-crossover-study-designs.html#cb63-1"></a>mod_ovdisp_reg &lt;-<span class="st"> </span><span class="kw">glm</span>(all <span class="op">~</span><span class="st"> </span>tmean, <span class="dt">data =</span> obs, <span class="dt">family =</span> <span class="st">&quot;quasipoisson&quot;</span>)</span></code></pre></div>
<p>When you use this family, there will be some new information in the summary
for the model object. It will now include a dispersion parameter (<span class="math inline">\(\phi\)</span>). If this
is close to 1, then the data were close to the assumed variance for a Poisson
distribution (i.e., there was little evidence of overdispersion). In the
example, the overdispersion is around 5, suggesting the data are overdispersed
(this might come down some when we start including independent variables that
explain some of the variation in the outcome variable, like long-term and
seasonal trends).</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="time-series-case-crossover-study-designs.html#cb64-1"></a><span class="kw">summary</span>(mod_ovdisp_reg)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = all ~ tmean, family = &quot;quasipoisson&quot;, data = obs)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.5945  -1.6365  -0.1167   1.3652  12.2221  
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.2445409  0.0044087  1189.6   &lt;2e-16 ***
## tmean       -0.0147728  0.0003543   -41.7   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 5.006304)
## 
##     Null deviance: 49297  on 8278  degrees of freedom
## Residual deviance: 40587  on 8277  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>If you compare the estimates of the temperature coefficient from the Poisson
regression with those when you allow for overdispersion, you’ll see something
interesting:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="time-series-case-crossover-study-designs.html#cb66-1"></a><span class="kw">tidy</span>(mod_pois_reg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb66-2"><a href="time-series-case-crossover-study-designs.html#cb66-2"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;tmean&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   term  estimate std.error statistic p.value
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 tmean  -0.0148  0.000158     -93.3       0</code></pre>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="time-series-case-crossover-study-designs.html#cb68-1"></a><span class="kw">tidy</span>(mod_ovdisp_reg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb68-2"><a href="time-series-case-crossover-study-designs.html#cb68-2"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;tmean&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   term  estimate std.error statistic p.value
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 tmean  -0.0148  0.000354     -41.7       0</code></pre>
<p>The central estimate (<code>estimate</code> column) is very similar. However, the estimated
standard error is larger when the model allows for overdispersion. This
indicates that the Poisson model was too simple, and that its inherent
assumption that data were not overdispersed was problematic. If you naively used
a Poisson regression in this case, then you would estimate a confidence
interval on the temperature coefficient that would be too narrow. This could
cause you to conclude that the estimate was statistically significant when
you should not have (although in this case, the estimate is statistically
significant under both models).</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Change your function call to include control for day of week.</strong></li>
</ol>
<p>Day of week is included in the data as a categorical variable, using a
data type in R called a factor. You are now essentially fitting this model:</p>
<p><span class="math inline">\(log(Y)=\beta_{0}+\beta_{1}X1+\gamma^{&#39;}X2\)</span>,</p>
<p>where <span class="math inline">\(X2\)</span> is a categorical variable for day of the week and <span class="math inline">\(\gamma^{&#39;}\)</span>
represents a vector of parameters associated with each category.</p>
<p>It is pretty straightforward to include factors as independent variables in calls
to <code>glm</code>: you just add the column name to the list of other independent variables
with a <code>+</code>. In this case, we need to do one more step: earlier, we added order to
<code>dow</code>, so it would “remember” the order of the week days (Monday before Tuesday,
etc.). However, we need to strip off this order before we include the factor in
the <code>glm</code> call. One way to do this is with the <code>factor</code> call, specifying
<code>ordered = FALSE</code>. Here is the full call to fit this model:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="time-series-case-crossover-study-designs.html#cb70-1"></a>mod_ctrl_dow &lt;-<span class="st"> </span><span class="kw">glm</span>(all <span class="op">~</span><span class="st"> </span>tmean <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(dow, <span class="dt">ordered =</span> <span class="ot">FALSE</span>), </span>
<span id="cb70-2"><a href="time-series-case-crossover-study-designs.html#cb70-2"></a>                    <span class="dt">data =</span> obs, <span class="dt">family =</span> <span class="st">&quot;quasipoisson&quot;</span>)</span></code></pre></div>
<p>When you look at the summary for the model object, you can see that the
model has fit a separate model parameter for six of the seven weekdays. The one
weekday that isn’t fit (Sunday in this case) serves as a baseline —these
estimates specify how the log of the expected mortality count is expected to
differ on, for example, Monday versus Sunday (by about 0.03), if the temperature
is the same for the two days.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="time-series-case-crossover-study-designs.html#cb71-1"></a><span class="kw">summary</span>(mod_ctrl_dow)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = all ~ tmean + factor(dow, ordered = FALSE), family = &quot;quasipoisson&quot;, 
##     data = obs)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -6.3211  -1.6476  -0.1313   1.3549  12.5286  
## 
## Coefficients:
##                                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                      5.2208502  0.0065277 799.804  &lt; 2e-16 ***
## tmean                           -0.0147723  0.0003538 -41.750  &lt; 2e-16 ***
## factor(dow, ordered = FALSE)Mon  0.0299282  0.0072910   4.105 4.08e-05 ***
## factor(dow, ordered = FALSE)Tue  0.0292575  0.0072920   4.012 6.07e-05 ***
## factor(dow, ordered = FALSE)Wed  0.0255224  0.0073020   3.495 0.000476 ***
## factor(dow, ordered = FALSE)Thu  0.0269580  0.0072985   3.694 0.000222 ***
## factor(dow, ordered = FALSE)Fri  0.0355431  0.0072834   4.880 1.08e-06 ***
## factor(dow, ordered = FALSE)Sat  0.0181489  0.0073158   2.481 0.013129 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for quasipoisson family taken to be 4.992004)
## 
##     Null deviance: 49297  on 8278  degrees of freedom
## Residual deviance: 40434  on 8271  degrees of freedom
## AIC: NA
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>You can also see from this summary that the coefficients for the day of the
week are all statistically significant. Even though we didn’t see a big
difference in mortality counts by day of week in our exploratory analysis,
this suggests that it does help explain some variance in mortality observations
and will likely be worth including in the final model.</p>
<p>The model now includes day of week when fitting an expected mortality count
for each observation. As a result, if you plot fitted values of expected
mortality versus mean daily temperature, you’ll see some “hoppiness” in the
fitted line:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="time-series-case-crossover-study-designs.html#cb73-1"></a>mod_ctrl_dow <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb73-2"><a href="time-series-case-crossover-study-designs.html#cb73-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb73-3"><a href="time-series-case-crossover-study-designs.html#cb73-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb73-4"><a href="time-series-case-crossover-study-designs.html#cb73-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> all), <span class="dt">alpha =</span> <span class="fl">0.4</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb73-5"><a href="time-series-case-crossover-study-designs.html#cb73-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">exp</span>(.fitted)), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb73-6"><a href="time-series-case-crossover-study-designs.html#cb73-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Mean daily temperature&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Expected mortality count&quot;</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>This is because each fitted value is also incorporating the expected influence
of day of week on the mortality count, and that varies across the observations
(i.e., you could have two days with the same temperature, but different
expected mortality from the model, because they occur on different days).</p>
<p>If you plot the model fits separately for each day of the week, you’ll see that
the line is smooth across all observations from the same day of the week:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="time-series-case-crossover-study-designs.html#cb74-1"></a>mod_ctrl_dow <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb74-2"><a href="time-series-case-crossover-study-designs.html#cb74-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb74-3"><a href="time-series-case-crossover-study-designs.html#cb74-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tmean)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb74-4"><a href="time-series-case-crossover-study-designs.html#cb74-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> all), <span class="dt">alpha =</span> <span class="fl">0.4</span>, <span class="dt">size =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb74-5"><a href="time-series-case-crossover-study-designs.html#cb74-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="kw">exp</span>(.fitted)), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb74-6"><a href="time-series-case-crossover-study-designs.html#cb74-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Mean daily temperature&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Expected mortality count&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb74-7"><a href="time-series-case-crossover-study-designs.html#cb74-7"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>obs<span class="op">$</span>dow)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p><em>Wrapping up</em></p>
<p>At this point, the coefficient estimates suggests that risk of mortality
tends to decrease as temperature increases. Do you think this is reasonable?
What else might be important to build into the model based on your analysis
up to this point?</p>
</div>
<div id="chapter-vocabulary" class="section level2">
<h2><span class="header-section-number">3.4</span> Chapter vocabulary</h2>
<p>Each class will start with a vocabulary quiz on a select number of the words
from the chapter’s vocabulary list. The vocabulary words for this chapter are:</p>
<ul>
<li>time-series study design</li>
<li>case-crossover study design</li>
<li>exposure</li>
<li>health outcome</li>
<li>confounder</li>
<li>study period</li>
<li>seasonal trends</li>
<li>long-term trends</li>
<li>error distribution</li>
<li>generalized linear model (GLM)</li>
<li>link function</li>
<li>overdispersed</li>
<li>categorical variable</li>
<li>spline</li>
<li>natural cubic spline</li>
<li>distributed lag</li>
<li>cross-basis term</li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-armstrong2014conditional">
<p>Armstrong, Ben G, Antonio Gasparrini, and Aurelio Tobias. 2014. “Conditional Poisson Models: A Flexible Alternative to Conditional Logistic Case Cross-over Analysis.” <em>BMC Medical Research Methodology</em> 14 (1): 122.</p>
</div>
<div id="ref-chang2018r">
<p>Chang, Winston. 2018. <em>R Graphics Cookbook: Practical Recipes for Visualizing Data</em>. O’Reilly Media.</p>
</div>
<div id="ref-healy2018data">
<p>Healy, Kieran. 2018. <em>Data Visualization: A Practical Introduction</em>. Princeton University Press.</p>
</div>
<div id="ref-robinson2014broom">
<p>Robinson, David. 2014. “Broom: An R Package for Converting Statistical Analysis Objects into Tidy Data Frames.” <em>arXiv Preprint arXiv:1412.3565</em>.</p>
</div>
<div id="ref-vicedo2019hands">
<p>Vicedo-Cabrera, Ana M, Francesco Sera, and Antonio Gasparrini. 2019. “Hands-on Tutorial on a Modeling Framework for Projections of Climate Change Impacts on Health.” <em>Epidemiology</em> 30 (3): 321–29.</p>
</div>
<div id="ref-wickham2016r">
<p>Wickham, Hadley, and Garrett Grolemund. 2016. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. " O’Reilly Media, Inc.".</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="courseinfo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="generalized-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["adv_epi_analysis.pdf", "adv_epi_analysis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
