<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Mixed models | Advanced Epidemiological Analysis</title>
  <meta name="description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Mixed models | Advanced Epidemiological Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Mixed models | Advanced Epidemiological Analysis" />
  
  <meta name="twitter:description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  

<meta name="author" content="Andreas M. Neophytou and G. Brooke Anderson" />


<meta name="date" content="2022-08-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="some-approaches-for-confounding.html"/>
<link rel="next" href="instrumental-variables.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Epidemiological Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.1</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="courseinfo.html"><a href="courseinfo.html"><i class="fa fa-check"></i><b>2</b> Course information</a>
<ul>
<li class="chapter" data-level="2.1" data-path="courseinfo.html"><a href="courseinfo.html#course-learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Course learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="courseinfo.html"><a href="courseinfo.html#meeting-time-and-place"><i class="fa fa-check"></i><b>2.2</b> Meeting time and place</a></li>
<li class="chapter" data-level="2.3" data-path="courseinfo.html"><a href="courseinfo.html#class-structure-and-expectations"><i class="fa fa-check"></i><b>2.3</b> Class Structure and Expectations</a></li>
<li class="chapter" data-level="2.4" data-path="courseinfo.html"><a href="courseinfo.html#course-grading"><i class="fa fa-check"></i><b>2.4</b> Course grading</a></li>
<li class="chapter" data-level="2.5" data-path="courseinfo.html"><a href="courseinfo.html#course-schedule"><i class="fa fa-check"></i><b>2.5</b> Course Schedule</a></li>
<li class="chapter" data-level="2.6" data-path="courseinfo.html"><a href="courseinfo.html#textbooks-and-course-materials"><i class="fa fa-check"></i><b>2.6</b> Textbooks and Course Materials</a></li>
<li class="chapter" data-level="2.7" data-path="courseinfo.html"><a href="courseinfo.html#prerequisites-and-preparation"><i class="fa fa-check"></i><b>2.7</b> Prerequisites and Preparation</a></li>
<li class="chapter" data-level="2.8" data-path="courseinfo.html"><a href="courseinfo.html#academic-honesty"><i class="fa fa-check"></i><b>2.8</b> Academic Honesty</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html"><i class="fa fa-check"></i><b>3</b> Time series / case-crossover studies</a>
<ul>
<li class="chapter" data-level="3.1" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#readings"><i class="fa fa-check"></i><b>3.1</b> Readings</a></li>
<li class="chapter" data-level="3.2" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#time-series-and-case-crossover-study-designs"><i class="fa fa-check"></i><b>3.2</b> Time series and case-crossover study designs</a></li>
<li class="chapter" data-level="3.3" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#time-series-data"><i class="fa fa-check"></i><b>3.3</b> Time series data</a></li>
<li class="chapter" data-level="3.4" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>3.4</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="3.5" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#statistical-modeling-for-a-time-series-study"><i class="fa fa-check"></i><b>3.5</b> Statistical modeling for a time series study</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#readings-1"><i class="fa fa-check"></i><b>4.1</b> Readings</a></li>
<li class="chapter" data-level="4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#splines-in-glms"><i class="fa fa-check"></i><b>4.2</b> Splines in GLMs</a></li>
<li class="chapter" data-level="4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#distributed-lags-and-cross-basis-functions-in-glms"><i class="fa fa-check"></i><b>4.3</b> Distributed lags and cross-basis functions in GLMs</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="natural-experiments.html"><a href="natural-experiments.html"><i class="fa fa-check"></i><b>5</b> Natural experiments</a>
<ul>
<li class="chapter" data-level="5.1" data-path="natural-experiments.html"><a href="natural-experiments.html#readings-2"><i class="fa fa-check"></i><b>5.1</b> Readings</a></li>
<li class="chapter" data-level="5.2" data-path="natural-experiments.html"><a href="natural-experiments.html#natural-experiments-1"><i class="fa fa-check"></i><b>5.2</b> Natural experiments</a></li>
<li class="chapter" data-level="5.3" data-path="natural-experiments.html"><a href="natural-experiments.html#interrupted-time-series"><i class="fa fa-check"></i><b>5.3</b> Interrupted time series</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html"><i class="fa fa-check"></i><b>6</b> Estimating health impacts</a>
<ul>
<li class="chapter" data-level="6.1" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html#readings-3"><i class="fa fa-check"></i><b>6.1</b> Readings</a></li>
<li class="chapter" data-level="6.2" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html#attributable-risk-and-attributable-number"><i class="fa fa-check"></i><b>6.2</b> Attributable risk and attributable number</a></li>
<li class="chapter" data-level="6.3" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html#quantifying-potential-health-impacts-under-different-scenarios"><i class="fa fa-check"></i><b>6.3</b> Quantifying potential health impacts under different scenarios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html"><i class="fa fa-check"></i><b>7</b> Longitudinal cohort study designs</a>
<ul>
<li class="chapter" data-level="7.1" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#readings-4"><i class="fa fa-check"></i><b>7.1</b> Readings</a></li>
<li class="chapter" data-level="7.2" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#longitudinal-cohort-data"><i class="fa fa-check"></i><b>7.2</b> Longitudinal cohort data</a></li>
<li class="chapter" data-level="7.3" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#coding-a-survival-analysis"><i class="fa fa-check"></i><b>7.3</b> Coding a survival analysis</a></li>
<li class="chapter" data-level="7.4" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#handling-complexity"><i class="fa fa-check"></i><b>7.4</b> Handling complexity</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#recurrent-outcome-and-time-varying-exposures"><i class="fa fa-check"></i><b>7.4.1</b> Recurrent outcome and time varying-exposures</a></li>
<li class="chapter" data-level="7.4.2" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#multi-level-exposure"><i class="fa fa-check"></i><b>7.4.2</b> Multi-level exposure</a></li>
<li class="chapter" data-level="7.4.3" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#time-varying-coefficients"><i class="fa fa-check"></i><b>7.4.3</b> Time-varying coefficients</a></li>
<li class="chapter" data-level="7.4.4" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#using-survey-data-e.g.-nhanes"><i class="fa fa-check"></i><b>7.4.4</b> Using survey data (e.g. NHANES)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html"><i class="fa fa-check"></i><b>8</b> Some approaches for confounding</a>
<ul>
<li class="chapter" data-level="8.1" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#readings-5"><i class="fa fa-check"></i><b>8.1</b> Readings</a></li>
<li class="chapter" data-level="8.2" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#propensity-scores-and-inverse-probability-weighting"><i class="fa fa-check"></i><b>8.2</b> Propensity scores and inverse probability weighting</a></li>
<li class="chapter" data-level="8.3" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#more-ways-to-use-propensity-scores"><i class="fa fa-check"></i><b>8.3</b> More ways to use propensity scores</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>9</b> Mixed models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mixed-models.html"><a href="mixed-models.html#readings-6"><i class="fa fa-check"></i><b>9.1</b> Readings</a></li>
<li class="chapter" data-level="9.2" data-path="mixed-models.html"><a href="mixed-models.html#introduction-to-mixed-models"><i class="fa fa-check"></i><b>9.2</b> Introduction to mixed models</a></li>
<li class="chapter" data-level="9.3" data-path="mixed-models.html"><a href="mixed-models.html#mixed-models-with-random-intercepts"><i class="fa fa-check"></i><b>9.3</b> Mixed models with random intercepts</a></li>
<li class="chapter" data-level="9.4" data-path="mixed-models.html"><a href="mixed-models.html#adding-random-effect-slopes"><i class="fa fa-check"></i><b>9.4</b> Adding random effect slopes</a></li>
<li class="chapter" data-level="9.5" data-path="mixed-models.html"><a href="mixed-models.html#some-final-points-on-mixed-effects-models"><i class="fa fa-check"></i><b>9.5</b> Some final points on mixed effects models:</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="instrumental-variables.html"><a href="instrumental-variables.html"><i class="fa fa-check"></i><b>10</b> Instrumental variables</a>
<ul>
<li class="chapter" data-level="10.1" data-path="instrumental-variables.html"><a href="instrumental-variables.html#readings-7"><i class="fa fa-check"></i><b>10.1</b> Readings</a></li>
<li class="chapter" data-level="10.2" data-path="instrumental-variables.html"><a href="instrumental-variables.html#introduction-to-instrumental-variables"><i class="fa fa-check"></i><b>10.2</b> Introduction to instrumental variables</a></li>
<li class="chapter" data-level="10.3" data-path="instrumental-variables.html"><a href="instrumental-variables.html#the-nhefs-data"><i class="fa fa-check"></i><b>10.3</b> The NHEFS data</a></li>
<li class="chapter" data-level="10.4" data-path="instrumental-variables.html"><a href="instrumental-variables.html#identifying-an-instrumental-variable-checking-the-iv-conditions-and-the-standard-iv-estimand"><i class="fa fa-check"></i><b>10.4</b> Identifying an instrumental variable, checking the IV conditions and the standard IV estimand</a></li>
<li class="chapter" data-level="10.5" data-path="instrumental-variables.html"><a href="instrumental-variables.html#the-two-stage-least-squares-estimator"><i class="fa fa-check"></i><b>10.5</b> The two-stage-least-squares estimator</a></li>
<li class="chapter" data-level="10.6" data-path="instrumental-variables.html"><a href="instrumental-variables.html#sensitivity-analysis"><i class="fa fa-check"></i><b>10.6</b> Sensitivity analysis</a></li>
<li class="chapter" data-level="10.7" data-path="instrumental-variables.html"><a href="instrumental-variables.html#the-condition-of-homogenetity-or-alternative-condition-of-monotonictiy"><i class="fa fa-check"></i><b>10.7</b> The condition of homogenetity (or alternative condition of monotonictiy)</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>11</b> Causal inference</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Epidemiological Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mixed-models" class="section level1" number="9">
<h1><span class="header-section-number">Chapter 9</span> Mixed models</h1>
<div id="readings-6" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Readings</h2>
<p>The required readings for this chapter are:</p>
<ul>
<li><span class="citation"><a href="#ref-loucks2011associations" role="doc-biblioref">Loucks et al.</a> (<a href="#ref-loucks2011associations" role="doc-biblioref">2011</a>)</span> Uses mixed models to explore the relationship between
education level and blood pressure in the Framingham Offspring Study</li>
</ul>
<p>There are also some supplemental readings you may find useful.</p>
<ul>
<li><span class="citation"><a href="#ref-block2011proximity" role="doc-biblioref">Block et al.</a> (<a href="#ref-block2011proximity" role="doc-biblioref">2011</a>)</span> Another study that used mixed models to handle a repeated
measures outcome in the Framingham Offspring study (in this case, BMI, in
relation to proximity to food establishments)</li>
<li><span class="citation"><a href="#ref-rice2013short" role="doc-biblioref">Rice et al.</a> (<a href="#ref-rice2013short" role="doc-biblioref">2013</a>)</span> Another study that used mixed models to handle a repeated
measures outcome in the Framingham family of studies (in this case, lung
function, in relation to air pollution levels right before the exam)</li>
<li><span class="citation"><a href="#ref-gibbons2010advances" role="doc-biblioref">Gibbons, Hedeker, and DuToit</a> (<a href="#ref-gibbons2010advances" role="doc-biblioref">2010</a>)</span> A review of methodological approaches for repeated
measures data</li>
<li><span class="citation"><a href="#ref-gelman2006data" role="doc-biblioref">Gelman and Hill</a> (<a href="#ref-gelman2006data" role="doc-biblioref">2006</a>)</span> A classic textbook on the topic (with examples in R), if you
want a deeper dive</li>
</ul>
</div>
<div id="introduction-to-mixed-models" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Introduction to mixed models</h2>
<p>In all our previous models, we’ve been assuming that the observations are
independent of each other, at least after accounting for the role of any
of the covariates that were used in the model. However, this won’t always
be a safe assumption to make. Many types of data have a type of inherent
grouping (clustering), and in these cases observations are typically likely to be more
similar within a group that between different groups.</p>
<p>One example, which we’ll explore in this module, is when you have more than one
measurement on each study subject. These could be multiple measurements of the
same person (othen called <em>repeated measures</em>), as we’ll see in the case of some
outcomes in the Framingham Heart Study data. It could also be multiple
measurements within families (i.e., one data point per family member, grouped in
families), or multiple measurements per doctor (i.e., one data point per
patient, grouped by the patients’ doctors). In all these cases, observations
are likely more similar within a group than across groups, and as a result,
once you fit a model, the errors are likely to be correlated—for example,
if one measurement for a person has negative residual from the model prediction,
then it’s likely that the person’s other measurements, on average, are also
lower than their model predictions.</p>
<p>One way to address this type of data is to use a type of model called <em>mixed
models</em>. These can handle this clustering in the observations, while still
allowing you to model effects of different risk factors using a very similar
process to the one you’ve used in earlier models (a regression-based approach).</p>
<p>In this module, we’ll explore how you can understand, use, and code mixed
models. We’ll use the Framingham Heart Study data. Before, we looked at survival
outcomes in this dataset. We started with analysis with one observation per participant -
for example, we looked at the time from the baseline examination until
death, and there can only be one measurement (or censoring) for each person
for that outcome. Even in the time-varying setting survival outcomes have a certain
structure by definition where we don’t have to worry about correlation. A participant
will begin free of the outcome until they experience it, which can only occur once,or until
censored and this is true for every participant. Here, we’ll look at a value that
is measured at each examination—blood pressure. We have repeated measures of blood
pressure for each study subject, and we’ll investigate how those are associated with
one time-invariant variable (education level, which never changes for any
of the study subjects over examination periods) and several time-variant
variables (for example, BMI, which is recorded at all examinations).</p>
<p>We’ll start by creating a subset of just a few of the study subjects, so we can
get a close look at what happens with mixed models, especially the <em>random
effects</em> component that makes them different from the GLMs we’ve used in earlier
modules. We’ll start by creating our sample of subjects and do some exploratory
analysis of systolic blood pressure and some of its potential risk factors. In
the next section, we’ll build models that include random effects intercepts in
the next section of the chapter, starting with intercept-only models, and then
moving to models that estimate the effects of risk factors like education level
and BMI. In section after that, we’ll explore models that have random effects
for both the intercept and the slope term for age (i.e., for how blood pressure
evolves as people age).</p>
<p><em>Applied exercise: Creating a subset of subjects and performing exploratory analysis</em></p>
<p>Read the example cohort data in R and explore it to answer the following
question:</p>
<ol style="list-style-type: decimal">
<li>In a subset of fifteen subjects from the Framingham Heart Study (be sure
to select only subjects with three examinations, so we can explore variation
across repeated measures), how does systolic blood pressure relate to the
potential risk factors of sex, age, smoking status, BMI, and education level?</li>
</ol>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>In a subset of fifteen subjects from the Framingham Heart Study (be sure
to select only subjects with three examinations, so we can explore variation
across repeated measures), how does systolic blood pressure relate to the
potential risk factors of sex, age, smoking status, BMI, and education level?</strong></li>
</ol>
<p>Let’s start by looking at a subset of the Framingham Heart Study data. We’ll
randomly pick a few of the study subjects who had three examinations, and
we’ll use this subset to explore the idea of using a mixed model to account
for the inherent grouping in the data (three measurements for each study
subject). Later, we’ll expand these ideas to look at the full study population,
but it can be helpful to start by seeing what’s going on for just a few subjects
first, to understand the idea of random versus fixed effects.</p>
<p>First, you’ll want to re-load the study data, if you don’t have it handy in
your R session:</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="mixed-models.html#cb558-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse) <span class="co"># Loads all the tidyverse packages, including readr</span></span>
<span id="cb558-2"><a href="mixed-models.html#cb558-2" aria-hidden="true" tabindex="-1"></a>fhs <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/frmgham2.csv&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb558-3"><a href="mixed-models.html#cb558-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_all</span>(str_to_lower)</span></code></pre></div>
<p>Next, let’s create a sample of a few of the study subjects. We can use the
<code>slice_sample</code> function from the <code>dplyr</code> package to get a sample of rows from a
dataframe. Since we want to make sure that we sample at the level of study
subject, rather than measurement (otherwise, we’d probably only get one
measurement per sampled subject), we can nest the data first. This will reshape
the dataframe so that there’s one row per study subject (nesting by random ID)
rather than one per measurement. Once we’ve sampled, we can unnest to get back
to the original dimensions, with one row per measurement. We’ll also do a couple
of steps before sampling: we’ll create a new column that gives the number of
observations per person (which we’ll use when we create the sample to make sure
we’re sampling subjects with three examinations—we’re doing this to guarantee
we have multiple measurements for each subject in our small sample, but we’ll
take out this step when we move later to using the whole dataset). To make sure
that you get the same sample that we show here, you can set the seed to the same
number.</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="mixed-models.html#cb559-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">416</span>)</span>
<span id="cb559-2"><a href="mixed-models.html#cb559-2" aria-hidden="true" tabindex="-1"></a>fhs_sample <span class="ot">&lt;-</span> fhs <span class="sc">%&gt;%</span> </span>
<span id="cb559-3"><a href="mixed-models.html#cb559-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Relabel factor levels</span></span>
<span id="cb559-4"><a href="mixed-models.html#cb559-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sex =</span> <span class="fu">as_factor</span>(sex),</span>
<span id="cb559-5"><a href="mixed-models.html#cb559-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">sex =</span> <span class="fu">fct_recode</span>(sex, </span>
<span id="cb559-6"><a href="mixed-models.html#cb559-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">male =</span> <span class="st">&quot;1&quot;</span>, </span>
<span id="cb559-7"><a href="mixed-models.html#cb559-7" aria-hidden="true" tabindex="-1"></a>                          <span class="at">female =</span> <span class="st">&quot;2&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb559-8"><a href="mixed-models.html#cb559-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(randid) <span class="sc">%&gt;%</span> </span>
<span id="cb559-9"><a href="mixed-models.html#cb559-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate baseline age and number of observations for each study subject</span></span>
<span id="cb559-10"><a href="mixed-models.html#cb559-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb559-11"><a href="mixed-models.html#cb559-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb559-12"><a href="mixed-models.html#cb559-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Filter to only subjects with three examinations</span></span>
<span id="cb559-13"><a href="mixed-models.html#cb559-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">==</span> <span class="dv">3</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb559-14"><a href="mixed-models.html#cb559-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Limit to just the columns we&#39;ll use (to make the dataset simpler)</span></span>
<span id="cb559-15"><a href="mixed-models.html#cb559-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(randid, period, sex, age, sysbp,cursmoke, bmi, educ, time) <span class="sc">%&gt;%</span> </span>
<span id="cb559-16"><a href="mixed-models.html#cb559-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Nest the data, so there&#39;s one row per study subject, so we can sample </span></span>
<span id="cb559-17"><a href="mixed-models.html#cb559-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># by subject</span></span>
<span id="cb559-18"><a href="mixed-models.html#cb559-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nest</span>(<span class="at">cols =</span> <span class="sc">-</span>randid) <span class="sc">%&gt;%</span> </span>
<span id="cb559-19"><a href="mixed-models.html#cb559-19" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Sample a few study subjects</span></span>
<span id="cb559-20"><a href="mixed-models.html#cb559-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice_sample</span>(<span class="at">n =</span> <span class="dv">15</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb559-21"><a href="mixed-models.html#cb559-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Unnest, to get back to one row per measurement</span></span>
<span id="cb559-22"><a href="mixed-models.html#cb559-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(<span class="at">cols =</span> cols)</span>
<span id="cb559-23"><a href="mixed-models.html#cb559-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb559-24"><a href="mixed-models.html#cb559-24" aria-hidden="true" tabindex="-1"></a>fhs_sample</span></code></pre></div>
<pre><code>## # A tibble: 45 × 9
##     randid period sex      age sysbp cursmoke   bmi  educ  time
##      &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 7112885      1 female    37   126        0  25.9     2     0
##  2 7112885      2 female    43   126        0  28.5     2  2113
##  3 7112885      3 female    49   130        0  29.2     2  4327
##  4 9356685      1 male      64   176        0  24.9     3     0
##  5 9356685      2 male      70   174        0  22.4     3  2129
##  6 9356685      3 male      75   190        0  27.0     3  4164
##  7 4452358      1 female    59   141        0  25.3     1     0
##  8 4452358      2 female    65   165        0  27.4     1  2104
##  9 4452358      3 female    71   154        0  26.4     1  4286
## 10 9694232      1 female    48   155        0  28.5     1     0
## # … with 35 more rows</code></pre>
<p>This code results in a dataset of a few study subjects, with three measurements
for each study subject. In this module, we’ll be looking at some risk factors
for high blood pressure (hypertension). Blood pressure is measured through
measurements of both systolic blood pressure, which is the pressure on your
arteries during a heart beat, and diabolic blood pressure, which is the pressure
on your arteries between heart beats. We’ll focus on systolic blood
pressure, which is included in the data in the column <code>sysbp</code>.</p>
<p>Let’s make a plot of how systolic blood pressure varies across each of our
study subjects, looking at their measurements at different ages:</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="mixed-models.html#cb561-1" aria-hidden="true" tabindex="-1"></a>fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb561-2"><a href="mixed-models.html#cb561-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> sysbp, <span class="at">group =</span> randid, </span>
<span id="cb561-3"><a href="mixed-models.html#cb561-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> sex)) <span class="sc">+</span> </span>
<span id="cb561-4"><a href="mixed-models.html#cb561-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb561-5"><a href="mixed-models.html#cb561-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Systolic blood pressure (mmHg)&quot;</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-284-1.png" width="672" /></p>
<p>Within this sample, we see that there’s a lot of variation across the study
subjects in systolic blood pressure. Some of this variation is explained by age,
both within and between subjects—for example, someone who is younger at the
baseline examination tends to have lower measurements of blood pressure at all
examinations compared to someone who is older at the baseline examination, and
most subjects’ systolic blood pressure tends to increase as they age across
their three examinations. In this sample, there doesn’t seem to be a clear
pattern by sex (although it’s a bit hard to be definitive with this small
sample).</p>
<p>Let’s start by looking at some variables in the data that might be correlated
with systolic blood pressure. In this section, we’re aiming to build up to a
model that will let us explore the association between education level (<code>educ</code>)
and systolic blood pressure. We’ll also explore the association with some other
potential risk factors, including BMI, which we’ll also include as potential
confounders when we investiate the association with education level. For this,
we’ve picked a few factors, based on prior knowledge, that might be associated
with systolic blood pressure—sex, age, smoking status, and BMI We can start
with some exploratory analysis to see how they’re linked in this sample of
subjects.</p>
<p>First, the <code>GGally</code> package can produce a nice exploratory graph that includes
the univariate distribution of each column, plus correlations and scatterplots
to show the relationship between each pair of columns:</p>
<div class="sourceCode" id="cb562"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb562-1"><a href="mixed-models.html#cb562-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb562-2"><a href="mixed-models.html#cb562-2" aria-hidden="true" tabindex="-1"></a>fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb562-3"><a href="mixed-models.html#cb562-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(sex, age, cursmoke, bmi, educ, sysbp) <span class="sc">%&gt;%</span> </span>
<span id="cb562-4"><a href="mixed-models.html#cb562-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggpairs</span>()</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-285-1.png" width="672" /></p>
<p>Based on this, age is clearly correlated with systolic blood pressure, with
blood pressure tending to be higher at higher ages. BMI also seems to be
associated, with blood pressure tending to be higher at higher BMI. There are
also some smaller associations between smoking status (blood pressure tends to
be lower for current smokers, although keep in mind that smoking status looks
like it’s correlated with age, with current smokers tending to be younger) and
education level (blood pressure tends to be lower for higher education levels).</p>
<p>For a simpler graphic of these correlations, we can use the package
<code>ggcorrplot</code>, which can create a correlation plot. You first use <code>cor</code> (in base
R) to calculate the correlation matrix and then pass this to the <code>ggcorrplot</code>
function. Since only numeric values can be included when calculating the
correlation matrix, we’ll level sex out this time. This function shows only
correlations, but would be nice with larger datasets, which the <code>ggpairs</code>
function might struggle to fit quickly (because there are so many observations):</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="mixed-models.html#cb563-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggcorrplot)</span>
<span id="cb563-2"><a href="mixed-models.html#cb563-2" aria-hidden="true" tabindex="-1"></a>fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb563-3"><a href="mixed-models.html#cb563-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(age, cursmoke, bmi, educ, sysbp) <span class="sc">%&gt;%</span> </span>
<span id="cb563-4"><a href="mixed-models.html#cb563-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cor</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb563-5"><a href="mixed-models.html#cb563-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggcorrplot</span>(<span class="at">method =</span> <span class="st">&quot;circle&quot;</span>, <span class="at">type =</span> <span class="st">&quot;lower&quot;</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-286-1.png" width="672" /></p>
<p>We could also use beeswarm plots in our original data to explore how
education levels are associated with systolic blood pressure in that full
dataset:</p>
<div class="sourceCode" id="cb564"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb564-1"><a href="mixed-models.html#cb564-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggbeeswarm)</span>
<span id="cb564-2"><a href="mixed-models.html#cb564-2" aria-hidden="true" tabindex="-1"></a>fhs <span class="sc">%&gt;%</span> </span>
<span id="cb564-3"><a href="mixed-models.html#cb564-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(randid) <span class="sc">%&gt;%</span> </span>
<span id="cb564-4"><a href="mixed-models.html#cb564-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">educ =</span> <span class="fu">first</span>(educ), </span>
<span id="cb564-5"><a href="mixed-models.html#cb564-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">sysbp =</span> <span class="fu">mean</span>(sysbp, <span class="at">na.rm =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb564-6"><a href="mixed-models.html#cb564-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> educ, <span class="at">y =</span> sysbp, <span class="at">group =</span> educ)) <span class="sc">+</span> </span>
<span id="cb564-7"><a href="mixed-models.html#cb564-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_violin</span>() <span class="sc">+</span> </span>
<span id="cb564-8"><a href="mixed-models.html#cb564-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">width=</span><span class="fl">0.1</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-287-1.png" width="672" /></p>
</div>
<div id="mixed-models-with-random-intercepts" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Mixed models with random intercepts</h2>
<p><em>Applied exercise: Mixed models with random intercepts</em></p>
<p>Explore models with a random effect intercept for each study subject:</p>
<ol style="list-style-type: decimal">
<li>Fit an intercept-only fixed effects model to the sample of study subjects. Do errors tend to be correlated within each study subject from this model?</li>
<li>Next, try fitting a random effects intercept-only model to the same data. Has this resolved any issues with correlated errors within study subjects in the fixed effects model?</li>
<li>Now expand the mixed effects model that you just fit. First, just add a term for
age, then build one that includes terms for age, sex, BMI, smoking status, and
education. What do you conclude from these models? Focus particularly on how
systolic blood pressure is associated with two of the time-variant measures
(age and BMI) and on the time-invariant measure (education level).</li>
<li>Try fitting the final model (with a random effect intercept for each study
subject and terms for age, sex, BMI, smoking status, and education) to the
full dataset, rather than the sample of a few subjects. What can you conclude?</li>
</ol>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>Fit an intercept-only fixed effects model to the sample of study subjects. Do errors tend to be correlated within each study subject from this model?</strong></li>
</ol>
<p>If we fit a model with nothing but a fixed effect intercept, our predicted systolic
blood pressure would be the same for everyone. This is a very simple model to
specify—you can use the <code>glm</code> (or in this case <code>lm</code> since we are fitting a linear
model) function since we’re using only a fixed effect (more later on what that is,
but essentially it’s the type of effect we’ve been fitting in all the previous models),
and in the model formula, we only need to specify <code>1</code> for an intercept:</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="mixed-models.html#cb565-1" aria-hidden="true" tabindex="-1"></a>int_only_fe_mod <span class="ot">&lt;-</span> fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb565-2"><a href="mixed-models.html#cb565-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(sysbp <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> .) </span></code></pre></div>
<p>The model we are fitting here is the following:
<span class="math display">\[
Y_{ti} = \beta_{0} + \epsilon_{ti}
\]</span></p>
<p>where systolic blood pressure <span class="math inline">\(Y_{ti}\)</span> varies by participant <span class="math inline">\(i\)</span> and time-period
<span class="math inline">\(t\)</span> (3 time-periods for each of the 15 participants totaling 45 combinations
for <span class="math inline">\(Y_{ti}\)</span>), <span class="math inline">\(\beta_{0}\)</span> is the MLE (OLS) estimate for the intercept (essentially
the mean of all 45 observations) and <span class="math inline">\(\epsilon_{ti}\)</span> is the model residual for each
participant-specific time-period (each observation). We are assuming that
<span class="math inline">\(\epsilon_{ti} \sim N(0,\sigma^2)\)</span>, but also that they are all independent.</p>
<p>Let’s take a look at how predictions for this model compare to the observed data
for each study subject. One nice way to do that is to used faceting in ggplot to
create a small plot for each study subject, so we can focus on each individual’s
set of repeated measures:</p>
<div class="sourceCode" id="cb566"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb566-1"><a href="mixed-models.html#cb566-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb566-2"><a href="mixed-models.html#cb566-2" aria-hidden="true" tabindex="-1"></a>int_only_fe_mod <span class="sc">%&gt;%</span> </span>
<span id="cb566-3"><a href="mixed-models.html#cb566-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">data =</span> fhs_sample) <span class="sc">%&gt;%</span> </span>
<span id="cb566-4"><a href="mixed-models.html#cb566-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">color =</span> sex)) <span class="sc">+</span> </span>
<span id="cb566-5"><a href="mixed-models.html#cb566-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> sysbp), <span class="at">linetype =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb566-6"><a href="mixed-models.html#cb566-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb566-7"><a href="mixed-models.html#cb566-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Systolic blood pressure (mmHg)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb566-8"><a href="mixed-models.html#cb566-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> randid, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-289-1.png" width="672" /></p>
<p>In this plot, the solid lines show the observed data for each person in the
sample (again, each person’s data is shown in one small plot). The dotted line
shows the predicted value based on the (intercept-only) model. You can see that
<em>everyone</em> has the same predicted systolic blood pressure—it’s just the
estimated coefficient for the intercept from the model. But some people tend to
have higher-than-average blood pressure, regardless of their age, and some tend
to have lower-than-average blood pressure. For these people, the error in the
model (the residual between the fitted and predicted values) is always in the
same direction. For example, if someone tends to have blood pressure that’s
higher than their predicted value in their first examination, they also tend to
have blood pressure that’s higher than their predicted value for all other
examinations, and vice-versa for people with lower-than-average blood pressure.
In other words, the model errors are <em>correlated</em> within each study subject, and
so if we fit the model to all the data without accounting for this, we’ll have
issues with the assumption that observations are independent. Instead, they’re
clustered by study subject, with measurements tending to be more similar when
you compare different examinations within the same subject than when you compare
measurements from different subjects.</p>
<p>We can account for this clustering in the data by using a type of model called a
mixed model. (There are lots of different names for this type of model that you
might see, including random effects models and mixed effects models.) These are
called mixed models because they mix two types of effects: fixed effects (which
are what we’ve been fitting in all our models so far) and something called
<em>random effects</em>. A random effect allows for some variation in an effect across
some grouping factor in the data—in our case, the study subjects. It’s
constrained to follow some distribution—in other words, we might assume that
intercepts are different across each study subject, but come from a normal
distribution centered at the overall intercept.</p>
<p>This constraint creates the difference between fitting a random effect intercept
model (where a random effect for the intercept allows the intercept to be
different for each study subject) and just including a fixed effect for the
study subject ID (which would create a completely different intercept for each
study subject, without any constraints on those intercept estimates). This
constraint also helps us if we want to infer or predict to units that weren’t in
the study—in other words, to people who weren’t study subjects. If we fit a
separate fixed effect intercept for each person in the study, we wouldn’t be
able to predict for new people, because we wouldn’t have an intercept estimate
for them. The random effects model assumes (through this constraint on the
random effect) that the average difference between each study subject’s
intercept and the overall intercept is zero, and that those differences are
normally distributed, so you can build on these assumptions to predict outcomes
for people not included in the original analysis.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Next, try fitting a random effects intercept-only model to the same data. Has this resolved any issues with correlated errors within study subjects in the fixed effects model?</strong></li>
</ol>
<p>Let’s try fitting a random effects intercept model to the data and see how our
predictions differ compared to the intercept-only fixed effects model we just fit.
We can use the <code>lmer</code> function from the <code>lme4</code> package in R to do this. Within
this function, we will specify the <em>systematic</em> part of the model the same as
we did with <code>lm</code> or <code>glm</code>—this is the part with the fixed effects for the model,
which in this case is only an intercept (<code>1</code>). We can then fit the random
effect for the grouping variable (study subject) by adding it to the model formula
inside parentheses, with the elements we want to include first (<code>1</code> for only
an intercept random effect), and then a bar, and then the column that gives
the grouping variable (<code>randid</code> for the study subject): <code>(1 | randid)</code>.</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="mixed-models.html#cb567-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lme4)</span>
<span id="cb567-2"><a href="mixed-models.html#cb567-2" aria-hidden="true" tabindex="-1"></a>int_only_mm_mod <span class="ot">&lt;-</span> fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb567-3"><a href="mixed-models.html#cb567-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> randid), <span class="at">data =</span> .) </span></code></pre></div>
<p>The model we are fitting here is
<span class="math display">\[
Y_{ti} = \beta_{0} + b_{i} + \epsilon_{ti}
\]</span>
where we have now added the random intercept term <span class="math inline">\(b{i}\)</span> that varies by participant
<span class="math inline">\(i\)</span>, but is constant over time for each participant. We are also assuming that
<span class="math inline">\(b_{i} \sim N(0,\sigma_{b}^2)\)</span> and <span class="math inline">\(\epsilon_{ti} \sim N(0,\sigma^2)\)</span> and that <span class="math inline">\(b_{i}\)</span>
and <span class="math inline">\(\epsilon_{ti}\)</span> are mutually independent. The overall variance of <span class="math inline">\(Y_{ti}\)</span> is
the sum of <span class="math inline">\(\sigma_{b}^2\)</span> and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Now we can look at the fitted values for each study subject again. To do this,
we can use an <code>augment</code> function (as we did when using <code>broom</code> functions with
<code>glm</code> objects), but we’ll need to load a new library (<code>broom.mixed</code>) that defines
those <code>broom</code> methods for the model output from these mixed models.</p>
<div class="sourceCode" id="cb568"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb568-1"><a href="mixed-models.html#cb568-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom.mixed)</span>
<span id="cb568-2"><a href="mixed-models.html#cb568-2" aria-hidden="true" tabindex="-1"></a>int_only_mm_mod <span class="sc">%&gt;%</span> </span>
<span id="cb568-3"><a href="mixed-models.html#cb568-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">data =</span> fhs_sample) <span class="sc">%&gt;%</span> </span>
<span id="cb568-4"><a href="mixed-models.html#cb568-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">color =</span> sex)) <span class="sc">+</span> </span>
<span id="cb568-5"><a href="mixed-models.html#cb568-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> sysbp), <span class="at">linetype =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb568-6"><a href="mixed-models.html#cb568-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb568-7"><a href="mixed-models.html#cb568-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Systolic blood pressure (mmHg)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb568-8"><a href="mixed-models.html#cb568-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> randid, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-291-1.png" width="672" /></p>
<p>You can see that this has really reduced our prediction errors—the predicted
values are now much closer to the observed values for each study subject,
because now each person has their own intercept. Further, it’s eliminated the
correlation in errors. Each study subject now tends to have an equal number of
measurements that are over- versus under-predicted, since we’ve allowed the
estimated intercept to be subject-specific.</p>
<p>Let’s take a look at the output of this model a bit more. First, we can use
<code>coef</code> to pull out the coefficients for each unit for which we fit a random
effect—in this case, for each study subject:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="mixed-models.html#cb569-1" aria-hidden="true" tabindex="-1"></a>int_only_mm_mod <span class="sc">%&gt;%</span></span>
<span id="cb569-2"><a href="mixed-models.html#cb569-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coef</span>() </span></code></pre></div>
<pre><code>## $randid
##         (Intercept)
## 11252      132.9810
## 984473     150.3447
## 1705869    181.3100
## 1778003    141.5182
## 2963281    132.4022
## 3071444    134.1386
## 4227351    123.4310
## 4452358    152.0811
## 7010106    158.5925
## 7112885    129.5083
## 7409622    129.3636
## 7434568    136.4538
## 8638285    134.1386
## 9356685    175.2327
## 9694232    146.0038
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
<p>The <code>(Intercept)</code> column is the only one here, since we only fit an intercept.
This is incorporating, for each study subject, both the overall (fixed effect)
intercept that we fit in the model, as well as how that subject’s intercept
randomly varies from the overall one, or in other words the <span class="math inline">\(\beta_{0} + \b_{i}\)</span>
for each participant <span class="math inline">\(i\)</span>. We can see that these subject-specific intercepts
range from the 120s through the 180s.</p>
<p>Next, we can look at a summary of the model as a whole:</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="mixed-models.html#cb571-1" aria-hidden="true" tabindex="-1"></a>int_only_mm_mod <span class="sc">%&gt;%</span></span>
<span id="cb571-2"><a href="mixed-models.html#cb571-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: sysbp ~ 1 + (1 | randid)
##    Data: .
## 
## REML criterion at convergence: 378
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.9465 -0.3359 -0.1001  0.6979  1.7872 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  randid   (Intercept) 333.2    18.25   
##  Residual             151.8    12.32   
## Number of obs: 45, groups:  randid, 15
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  143.833      5.059   28.43</code></pre>
<p>This give some information about both the fixed and random effects (again, in
this case, just an intercept for each). The fixed effect intercept is
143.833—this is around the average blood pressure for all measurements in this
sample. The section on the random effects gives some information about
how variation from this intercept can be divided into variation based on the
grouping unit (study subject) or other variation, not explained by differences
between people (this could include variation from other
factors that we haven’t included in our model yet, like age or BMI).</p>
<p>You can see from this section that the total variance (_{b}^2 + ^2)
is 333.2 + 151.8 = 485. A lot of this (333.2 / 485 = 0.69, or about 69%) results
from variation between subjects (<span class="math inline">\(\sigma_{b}^2\)</span>), but there’s still some variance
that comes from within-subject variation (variation in blood pressure measurements
from one examination to another for the same person, ^2).</p>
<p>The <code>tidy</code> method for this class will pull out information on both the random
and fixed effect, including a column named <code>effect</code> that lets you extract only
fixed or only random estimates by filtering. The <code>estimate</code> that it’s giving for
the two random effect components (that from variation between study subjects,
“randid,” and that from remaining variation in the data, “Residual”) is the
standard deviation column given in the summary output for the model; these values
are <span class="math inline">\(\sigma_{b}\)</span> and <span class="math inline">\(\sigma\)</span> resepctively and if you want to get the variances,
you could just square these values.</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="mixed-models.html#cb573-1" aria-hidden="true" tabindex="-1"></a>int_only_mm_mod <span class="sc">%&gt;%</span></span>
<span id="cb573-2"><a href="mixed-models.html#cb573-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 3 × 6
##   effect   group    term            estimate std.error statistic
##   &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 fixed    &lt;NA&gt;     (Intercept)        144.       5.06      28.4
## 2 ran_pars randid   sd__(Intercept)     18.3     NA         NA  
## 3 ran_pars Residual sd__Observation     12.3     NA         NA</code></pre>
<p>The <code>augment</code> method will give results from the model at the level of each of your
original observations. For these models, it’s helpful to clarify that you want
to augment the original data (<code>fhs_sample</code>), rather than basing it on the model
matrix that’s the default. This will ensure that you can maintain information about
the <code>randid</code> for each row of the augmented data.</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="mixed-models.html#cb575-1" aria-hidden="true" tabindex="-1"></a>int_only_mm_mod <span class="sc">%&gt;%</span> </span>
<span id="cb575-2"><a href="mixed-models.html#cb575-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">data =</span> fhs_sample)</span></code></pre></div>
<pre><code>## # A tibble: 45 × 20
##     randid period sex      age sysbp cursmoke   bmi  educ  time .fitted  .resid
##      &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1 7112885      1 female    37   126        0  25.9     2     0    130.  -3.51 
##  2 7112885      2 female    43   126        0  28.5     2  2113    130.  -3.51 
##  3 7112885      3 female    49   130        0  29.2     2  4327    130.   0.492
##  4 9356685      1 male      64   176        0  24.9     3     0    175.   0.767
##  5 9356685      2 male      70   174        0  22.4     3  2129    175.  -1.23 
##  6 9356685      3 male      75   190        0  27.0     3  4164    175.  14.8  
##  7 4452358      1 female    59   141        0  25.3     1     0    152. -11.1  
##  8 4452358      2 female    65   165        0  27.4     1  2104    152.  12.9  
##  9 4452358      3 female    71   154        0  26.4     1  4286    152.   1.92 
## 10 9694232      1 female    48   155        0  28.5     1     0    146.   9.00 
## # … with 35 more rows, and 9 more variables: .hat &lt;dbl&gt;, .cooksd &lt;dbl&gt;,
## #   .fixed &lt;dbl&gt;, .mu &lt;dbl&gt;, .offset &lt;dbl&gt;, .sqrtXwt &lt;dbl&gt;, .sqrtrwt &lt;dbl&gt;,
## #   .weights &lt;dbl&gt;, .wtres &lt;dbl&gt;</code></pre>
<p>In this output, it’s taken the original <code>fhs_sample</code> data and added columns
based on the model, including columns with the estimated systolic blood pressure
for each observation (<code>.fitted</code>) and the fixed effect estimate (i.e., removing
the contribution from any random effects, so in this case the fixed effect
intercept; <code>.fixed</code>).</p>
<p>There are other specialized functions in <code>lme4</code> that you can use to extract
specific elements from the model object. For example, <code>fixef</code> will pull out only
the central estimates for the fixed effects, while <code>ranef</code> will pull out only
the random effect component (in this case, the difference for each subject
between the overall, fixed effect intercept estimate and their personal intercept
estimate). If you wanted, you could use these elements to add up to the
subject-specific estimates we got using <code>coef</code>.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Now expand the mixed effects model that you just fit. First, just add a
term for age, then build one that includes terms for age, sex, BMI, smoking
status, and education. What do you conclude from these models? Focus
particularly on how systolic blood pressure is associated with two of the
time-variant measures (age and BMI) and on the time-invariant measure (education
level).</strong></li>
</ol>
<p>The intercept-only mixed effects model helps us see how the idea of a random
effect works, but it’s often not particularly interesting, as we often are
more interested in how some risk factor is associated with an outcome, rather
than just how that outcome varies across measurements and study subjects.
In this section, we’ll build on the intercept-only model to include some
covariates.</p>
<p>Let’s start with age, since that was clearly linked with systolic blood pressure
in our exploratory analysis. There are a couple ways we could include
age—either using the age at each examination, or using a combination of the
age at baseline examine and the time since the baseline exam. We’ll do the
first, since conceptually it’s a bit simpler. We’ll therefore include age and an
intercept in the fixed part (which we can specify just as <code>age</code>—we don’t need
to add <code>1</code> for intercept since it’s the default if you put in any other
covariates). For the random effect, we’ll continue to only add a random
intercept for each study subject (<code>(1 | randid)</code>).</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="mixed-models.html#cb577-1" aria-hidden="true" tabindex="-1"></a>age_mm_mod <span class="ot">&lt;-</span> fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb577-2"><a href="mixed-models.html#cb577-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> age <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> randid), <span class="at">data =</span> .) </span></code></pre></div>
<p>Here we fit a similar model to the random intercept one, by simply addig the fixed
effect for age:
<span class="math display">\[
Y_{ti} = \beta_{0} + \beta_{1}X_{ti1} + b_{i} + \epsilon_{ti}
\]</span></p>
<p>Note that age <span class="math inline">\(X_{ti1}\)</span> also varies by participant and time-period.</p>
<p>Again, we can see how our predictions have changed in our set of sample
subjects:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="mixed-models.html#cb578-1" aria-hidden="true" tabindex="-1"></a>age_mm_mod <span class="sc">%&gt;%</span> </span>
<span id="cb578-2"><a href="mixed-models.html#cb578-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">data =</span> fhs_sample) <span class="sc">%&gt;%</span> </span>
<span id="cb578-3"><a href="mixed-models.html#cb578-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">color =</span> sex)) <span class="sc">+</span> </span>
<span id="cb578-4"><a href="mixed-models.html#cb578-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> sysbp), <span class="at">linetype =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb578-5"><a href="mixed-models.html#cb578-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb578-6"><a href="mixed-models.html#cb578-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fixed), <span class="at">linetype =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb578-7"><a href="mixed-models.html#cb578-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Systolic blood pressure (mmHg)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb578-8"><a href="mixed-models.html#cb578-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> randid, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-297-1.png" width="672" /></p>
<p>In this case, we’re showing three different lines, which help tease apart the
different components of the model. First, the solid line shows the observed data
at each examination. The dotted line (with the smallest dots) shows the
prediction for each study subject based only on the fixed effects estimates.
Since our model only includes an intercept and age for the fixed effects, you
can see that this line changes by age, but otherwise is at the same spot for
everyone. (To help see this, pick out two study subjects with examinations at
around the same ages, and this dotted line should look the same for both.)
Finally, the dashed line includes the random intercept for each study subject.
The slope of this line is the same as for the fixed effects estimate, but that
random, subject-specific intercept is allowing the line to move up or down to
fit the study subject’s data more closely. Again, we see that we would have
had correlated errors if we’d only used fixed effects, even with the term for
age, but that the random effects intercept seems to remove most of this issue.</p>
<p>We can look at the summary for this model:</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="mixed-models.html#cb579-1" aria-hidden="true" tabindex="-1"></a>age_mm_mod <span class="sc">%&gt;%</span> </span>
<span id="cb579-2"><a href="mixed-models.html#cb579-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: sysbp ~ age + (1 | randid)
##    Data: .
## 
## REML criterion at convergence: 373
## 
## Scaled residuals: 
##      Min       1Q   Median       3Q      Max 
## -2.31165 -0.43772 -0.08221  0.46569  1.62719 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  randid   (Intercept) 201.5    14.19   
##  Residual             156.9    12.53   
## Number of obs: 45, groups:  randid, 15
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 103.5535    15.5730   6.650
## age           0.7236     0.2698   2.682
## 
## Correlation of Fixed Effects:
##     (Intr)
## age -0.964</code></pre>
<p>Now you can see that there are fixed effects estimates for both the intercept
(the overall intercept) and for age. The age fixed effect gives the estimated
slope of the dotted and dashed lines we saw in the previous figure—that is,
the expected increase in systolic blood pressure for every extra year of age.</p>
<p>We can look at the random effects, as well. Again, we have estimates of the
variance components from both the between-subject variation (“randid,” <span class="math inline">\(\sigma_{b}^2\)</span>)
and from “left over” variation after accounting for study subject (“Residual,”
<span class="math inline">\(\sigma^2\)</span>). If you compare these values to the intercept-only mixed model, you
can see that the variance associated with the study subject is now lower (<span class="math inline">\(\sigma_{b}^2\)</span>).
This is because some of the original variation in blood pressure from one study
subject to another was related to variation in age among study subjects. Now that
we have a fixed term for age, we’ve managed to use that to explain some of the
variation in blood pressure when comparing different study subjects (although there’s
still plenty variation that’s explained by other subject-specific factors
that we haven’t included as fixed effects or maybe haven’t even measured,
as the estimate here for “randid” is still pretty high).</p>
<p>Let’s build the model up now to test one of our risk factors of interest, education.
Let’s also include model control for smoking, sex, and BMI. For all of these,
we have measures that span the range we might expect in our target population,
so we’ll include these using fixed effects terms:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="mixed-models.html#cb581-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod <span class="ot">&lt;-</span> fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb581-2"><a href="mixed-models.html#cb581-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> age <span class="sc">+</span> sex <span class="sc">+</span> bmi <span class="sc">+</span> cursmoke <span class="sc">+</span> educ <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> randid), </span>
<span id="cb581-3"><a href="mixed-models.html#cb581-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> .) </span>
<span id="cb581-4"><a href="mixed-models.html#cb581-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb581-5"><a href="mixed-models.html#cb581-5" aria-hidden="true" tabindex="-1"></a>full_mm_mod <span class="sc">%&gt;%</span> </span>
<span id="cb581-6"><a href="mixed-models.html#cb581-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: sysbp ~ age + sex + bmi + cursmoke + educ + (1 | randid)
##    Data: .
## 
## REML criterion at convergence: 343.4
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.7989 -0.4638  0.1184  0.4457  1.9807 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  randid   (Intercept) 162.2    12.73   
##  Residual             131.2    11.45   
## Number of obs: 45, groups:  randid, 15
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  63.0072    27.7817   2.268
## age           0.6831     0.2766   2.470
## sexfemale    -8.4050     8.1450  -1.032
## bmi           1.9633     0.6526   3.009
## cursmoke     -3.9953     7.6806  -0.520
## educ         -2.4729     4.5599  -0.542
## 
## Correlation of Fixed Effects:
##           (Intr) age    sexfml bmi    cursmk
## age       -0.548                            
## sexfemale -0.131 -0.065                     
## bmi       -0.734 -0.016 -0.070              
## cursmoke  -0.394  0.414  0.312  0.057       
## educ      -0.504 -0.079  0.087  0.364 -0.040</code></pre>
<p>The model now is</p>
<p><span class="math display">\[
Y_{ti} = \beta_{0} + \beta_{1}X_{ti1} + \beta_{2}X_{i2} + \beta_{3}X_{ti3} + \beta_{4}X_{ti4} + \beta_{5}X_{i5} + b_{i} + \epsilon_{ti}
\]</span></p>
<p>where age (<span class="math inline">\(X_{ti1}\)</span>), BMI (<span class="math inline">\(X_{ti3}\)</span>) and smoking (<span class="math inline">\(X_{ti4}\)</span>) vary by participant
and time period, whereas sex (<span class="math inline">\(X_{i2}\)</span>) and education level (<span class="math inline">\(X_{i5}\)</span>) only vary by
participant.</p>
<p>Since part of our aim is to explore the role of education, let’s look at the
<code>educ</code> fixed effect term (<span class="math inline">\(\beta_{5}\)</span>). Based on the estimate, it looks like systolic blood
pressure tends to be lower for people with higher levels of education.</p>
<p>We can’t directly calculate our confidence interval for this coefficient estimate
from the standard error, as we would for a GLM. Instead, we can use the
<code>confint.merMod</code> function that comes with the <code>lme4</code> package:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="mixed-models.html#cb583-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod <span class="sc">%&gt;%</span> </span>
<span id="cb583-2"><a href="mixed-models.html#cb583-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">confint.merMod</span>()</span></code></pre></div>
<pre><code>## Computing profile confidence intervals ...</code></pre>
<pre><code>##                   2.5 %     97.5 %
## .sig01        2.5909664  16.942640
## .sigma        8.8895592  15.390316
## (Intercept)   9.9000046 109.789814
## age           0.2071763   1.379707
## sexfemale   -22.2559971   5.357477
## bmi           0.7363315   3.065818
## cursmoke    -16.9445201  11.597196
## educ        -10.3674141   5.181958</code></pre>
<p>Based on this output, the relationship between education level and systolic
blood pressure is not statistically significant in our sample of study subjects,
as the estimated confidence intervals for the fixed effect of education include
zero. By contrast, age and BMI both seem to have a statistically significant
association with systolic blood pressure.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Try fitting the final model (with a random effect intercept for each study
subject and terms for age, sex, BMI, smoking status, and education) to the
full dataset, rather than the sample of a few subjects. What can you conclude?</strong></li>
</ol>
<p>We can expand this model to include all the study subjects now, to see if
something is detectable once we have that increased power:</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="mixed-models.html#cb586-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata <span class="ot">&lt;-</span> fhs <span class="sc">%&gt;%</span> </span>
<span id="cb586-2"><a href="mixed-models.html#cb586-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> age <span class="sc">+</span> sex <span class="sc">+</span> bmi <span class="sc">+</span> cursmoke <span class="sc">+</span> educ <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> randid), </span>
<span id="cb586-3"><a href="mixed-models.html#cb586-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> .) </span>
<span id="cb586-4"><a href="mixed-models.html#cb586-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb586-5"><a href="mixed-models.html#cb586-5" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata <span class="sc">%&gt;%</span> </span>
<span id="cb586-6"><a href="mixed-models.html#cb586-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: sysbp ~ age + sex + bmi + cursmoke + educ + (1 | randid)
##    Data: .
## 
## REML criterion at convergence: 96139.7
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2525 -0.5315 -0.0509  0.4585  6.0763 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  randid   (Intercept) 261.9    16.18   
##  Residual             156.1    12.49   
## Number of obs: 11282, groups:  randid, 4307
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 51.13151    2.35788  21.685
## age          0.84314    0.02096  40.224
## sex          2.49310    0.56084   4.445
## bmi          1.43106    0.05870  24.379
## cursmoke    -0.10641    0.43958  -0.242
## educ        -0.70184    0.27161  -2.584
## 
## Correlation of Fixed Effects:
##          (Intr) age    sex    bmi    cursmk
## age      -0.529                            
## sex      -0.439  0.014                     
## bmi      -0.704 -0.008  0.070              
## cursmoke -0.344  0.248  0.126  0.134       
## educ     -0.365  0.097  0.024  0.120  0.039</code></pre>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="mixed-models.html#cb588-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata <span class="sc">%&gt;%</span> </span>
<span id="cb588-2"><a href="mixed-models.html#cb588-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">confint.merMod</span>()</span></code></pre></div>
<pre><code>## Computing profile confidence intervals ...</code></pre>
<pre><code>##                  2.5 %     97.5 %
## .sig01      15.7414341 16.6192814
## .sigma      12.2871361 12.7055471
## (Intercept) 46.5100344 55.7515766
## age          0.8020672  0.8842684
## sex          1.3942208  3.5919872
## bmi          1.3160266  1.5460718
## cursmoke    -0.9677114  0.7551252
## educ        -1.2340390 -0.1696473</code></pre>
<p>Based on this assessment, there’s a small but statistically significant
association between education level at the baseline examination and
systolic blood pressure during the study. We can also see that systolic
blood pressure is significantly associated with age, sex, and BMI, so
these all may be risk factors for high blood pressure.</p>
<p>At this stage, you could explore more complex models. For example, there
may be an interaction between age and sex, where the evolution of blood pressure
during aging tends to be different for males versus females. We could add
an interaction term to the model to explore this:</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="mixed-models.html#cb591-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata2 <span class="ot">&lt;-</span> fhs <span class="sc">%&gt;%</span> </span>
<span id="cb591-2"><a href="mixed-models.html#cb591-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> age <span class="sc">*</span> sex <span class="sc">+</span> bmi <span class="sc">+</span> cursmoke <span class="sc">+</span> educ <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> randid), </span>
<span id="cb591-3"><a href="mixed-models.html#cb591-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> .) </span>
<span id="cb591-4"><a href="mixed-models.html#cb591-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb591-5"><a href="mixed-models.html#cb591-5" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata2 <span class="sc">%&gt;%</span> </span>
<span id="cb591-6"><a href="mixed-models.html#cb591-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: sysbp ~ age * sex + bmi + cursmoke + educ + (1 | randid)
##    Data: .
## 
## REML criterion at convergence: 96119.5
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2513 -0.5328 -0.0526  0.4612  6.0140 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  randid   (Intercept) 257.9    16.06   
##  Residual             156.7    12.52   
## Number of obs: 11282, groups:  randid, 4307
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 69.53601    4.35998  15.949
## age          0.52002    0.06779   7.671
## sex         -8.76656    2.31205  -3.792
## bmi          1.40663    0.05870  23.963
## cursmoke    -0.20762    0.43931  -0.473
## educ        -0.72180    0.27006  -2.673
## age:sex      0.20537    0.04093   5.018
## 
## Correlation of Fixed Effects:
##          (Intr) age    sex    bmi    cursmk educ  
## age      -0.889                                   
## sex      -0.874  0.924                            
## bmi      -0.448  0.076  0.097                     
## cursmoke -0.225  0.121  0.076  0.137              
## educ     -0.210  0.045  0.021  0.122  0.039       
## age:sex   0.842 -0.951 -0.970 -0.082 -0.047 -0.015</code></pre>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="mixed-models.html#cb593-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata2 <span class="sc">%&gt;%</span> </span>
<span id="cb593-2"><a href="mixed-models.html#cb593-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">confint.merMod</span>()</span></code></pre></div>
<pre><code>## Computing profile confidence intervals ...</code></pre>
<pre><code>##                   2.5 %     97.5 %
## .sig01       15.6135990 16.4926583
## .sigma       12.3097777 12.7300610
## (Intercept)  60.9726067 78.1195143
## age           0.3863850  0.6532505
## sex         -13.3311622 -4.2170025
## bmi           1.2915867  1.5216440
## cursmoke     -1.0683462  0.6533164
## educ         -1.2509263 -0.1926849
## age:sex       0.1248205  0.2862160</code></pre>
<p>There does seem to be a statistically significant interaction, although
accounting for it hasn’t made a big shift in our estimate of the fixed effect
of education level on systolic blood pressure.</p>
<p>We could also treat each level of education as a separate category, in case
there’s non-linearity between these four different designations of education
level and the association with systolic blood pressure:</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="mixed-models.html#cb596-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata3 <span class="ot">&lt;-</span> fhs <span class="sc">%&gt;%</span> </span>
<span id="cb596-2"><a href="mixed-models.html#cb596-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">educ =</span> <span class="fu">as_factor</span>(educ),</span>
<span id="cb596-3"><a href="mixed-models.html#cb596-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">educ =</span> <span class="fu">fct_recode</span>(educ, </span>
<span id="cb596-4"><a href="mixed-models.html#cb596-4" aria-hidden="true" tabindex="-1"></a>                           <span class="at">lowest =</span> <span class="st">&quot;1&quot;</span>, </span>
<span id="cb596-5"><a href="mixed-models.html#cb596-5" aria-hidden="true" tabindex="-1"></a>                           <span class="at">middle_low =</span> <span class="st">&quot;2&quot;</span>, </span>
<span id="cb596-6"><a href="mixed-models.html#cb596-6" aria-hidden="true" tabindex="-1"></a>                           <span class="at">middle_high =</span> <span class="st">&quot;3&quot;</span>, </span>
<span id="cb596-7"><a href="mixed-models.html#cb596-7" aria-hidden="true" tabindex="-1"></a>                           <span class="at">highest =</span> <span class="st">&quot;4&quot;</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb596-8"><a href="mixed-models.html#cb596-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> age<span class="sc">*</span>sex <span class="sc">+</span> bmi <span class="sc">+</span> cursmoke <span class="sc">+</span> educ <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">|</span> randid), </span>
<span id="cb596-9"><a href="mixed-models.html#cb596-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">data =</span> .) </span>
<span id="cb596-10"><a href="mixed-models.html#cb596-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb596-11"><a href="mixed-models.html#cb596-11" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata3 <span class="sc">%&gt;%</span> </span>
<span id="cb596-12"><a href="mixed-models.html#cb596-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: sysbp ~ age * sex + bmi + cursmoke + educ + (1 | randid)
##    Data: .
## 
## REML criterion at convergence: 96110.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2617 -0.5313 -0.0525  0.4602  6.0020 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  randid   (Intercept) 257.6    16.05   
##  Residual             156.7    12.52   
## Number of obs: 11282, groups:  randid, 4307
## 
## Fixed effects:
##                 Estimate Std. Error t value
## (Intercept)     68.06330    4.32861  15.724
## age              0.52688    0.06788   7.762
## sex             -8.79583    2.31364  -3.802
## bmi              1.41260    0.05877  24.034
## cursmoke        -0.22508    0.43936  -0.512
## educmiddle_low   0.49582    0.66671   0.744
## educmiddle_high -0.98811    0.80441  -1.228
## educhighest     -2.48161    0.91331  -2.717
## age:sex          0.20389    0.04093   4.981
## 
## Correlation of Fixed Effects:
##             (Intr) age    sex    bmi    cursmk edcmddl_l edcmddl_h edchgh
## age         -0.896                                                       
## sex         -0.879  0.923                                                
## bmi         -0.446  0.078  0.095                                         
## cursmoke    -0.222  0.120  0.075  0.136                                  
## educmddl_lw -0.143  0.067  0.013  0.088 -0.004                           
## edcmddl_hgh -0.103  0.030 -0.015  0.111  0.030  0.359                    
## educhighest -0.130  0.040  0.036  0.090  0.033  0.308     0.253          
## age:sex      0.849 -0.951 -0.970 -0.083 -0.046 -0.027    -0.005    -0.017</code></pre>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="mixed-models.html#cb598-1" aria-hidden="true" tabindex="-1"></a>full_mm_mod_alldata3 <span class="sc">%&gt;%</span> </span>
<span id="cb598-2"><a href="mixed-models.html#cb598-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">confint.merMod</span>()</span></code></pre></div>
<pre><code>## Computing profile confidence intervals ...</code></pre>
<pre><code>##                       2.5 %     97.5 %
## .sig01           15.6010488 16.4799563
## .sigma           12.3106597 12.7310252
## (Intercept)      59.5697205 76.5894555
## age               0.3929950  0.6601475
## sex             -13.3671197 -4.2482708
## bmi               1.2974221  1.5277259
## cursmoke         -1.0857556  0.6359310
## educmiddle_low   -0.8100710  1.8018785
## educmiddle_high  -2.5637284  0.5876557
## educhighest      -4.2705481 -0.6925419
## age:sex           0.1234191  0.2848179</code></pre>
<p>The decrease in expected blood pressure is most notable when you compare the
highest education group to the lowest education risk.</p>
</div>
<div id="adding-random-effect-slopes" class="section level2" number="9.4">
<h2><span class="header-section-number">9.4</span> Adding random effect slopes</h2>
<p>We can also add other random effects to our models. For example, if we think that
each of the people has a different evolution of blood pressure as they age, then
we could include a random effect for age. This will allow the slope fit for
age to vary across each person in the study. Again, this random effect estimate
will be constrained—it will have an average difference of 0 from the fixed
effect for age, and there will typically be a constraint on how these differences
from the fixed effect are distributed. This usually means that these estimates
will be a little more similar across people than if we fitted a fixed effect
estimate that allowed a separate slope by age for each person (which you could
do in a fixed effect by taking the interaction between subject ID and age).</p>
<p><em>Applied exercise: Mixed models with random intercepts</em></p>
<p>Explore models with a random effect intercept and random effect for age for each study subject:</p>
<ol style="list-style-type: decimal">
<li>Fit a model with a fixed effect for age, as well as random effects for both
age and sex, using the sample of a few study subjects. How do your predicts
change from the mixed model you fit in the previous section that had a fixed
effect term for age, but no random effect?</li>
</ol>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>Fit a model with a fixed effect for age, as well as random effects for both
age and sex. How do your predicts change from the mixed model you fit in the
previous section that had a fixed effect term for age, but no random effect?</strong></li>
</ol>
<p>We can fit a very similar model, but now in the random effects, we’ll include
a term for age, writing <code>(1 + age | randid)</code> for that component. (As a note, you
may get a warning when you fit this—since there are so few repeated measures
for each person, we’re probably pushing the model a bit to include a fixed
effect for age in this case, but it’s useful to know how to do this if you
have a larger set of repeated measures for each person, so we’d like to
cover the principle.)</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="mixed-models.html#cb601-1" aria-hidden="true" tabindex="-1"></a>age_mm_mod2 <span class="ot">&lt;-</span> fhs_sample <span class="sc">%&gt;%</span> </span>
<span id="cb601-2"><a href="mixed-models.html#cb601-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lmer</span>(sysbp <span class="sc">~</span> age <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">+</span> age <span class="sc">|</span> randid), <span class="at">data =</span> .) </span></code></pre></div>
<p>The model fitted here is
<span class="math display">\[
Y_{ti} = \beta_{0} + \beta_{1}X_{ti1} + b_{0i} + b_{1i}X_{ti1} + \epsilon_{ti}
\]</span>
with <span class="math inline">\(b_{1i}\)</span> being the added slope term for age and with the added assumption
that <span class="math inline">\(b_{1i} \sim N(0,\sigma_{b1}^2)\)</span> in addition to <span class="math inline">\(b_{0i} \sim N(0,\sigma_{b0}^2)\)</span>
and <span class="math inline">\(\epsilon_{ti} \sim N(0,\sigma^2)\)</span></p>
<p>We can take a look again at the predictions from this model:</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb602-1"><a href="mixed-models.html#cb602-1" aria-hidden="true" tabindex="-1"></a>age_mm_mod2 <span class="sc">%&gt;%</span> </span>
<span id="cb602-2"><a href="mixed-models.html#cb602-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">data =</span> fhs_sample) <span class="sc">%&gt;%</span> </span>
<span id="cb602-3"><a href="mixed-models.html#cb602-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">color =</span> sex)) <span class="sc">+</span> </span>
<span id="cb602-4"><a href="mixed-models.html#cb602-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> sysbp), <span class="at">linetype =</span> <span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb602-5"><a href="mixed-models.html#cb602-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted), <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb602-6"><a href="mixed-models.html#cb602-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fixed), <span class="at">linetype =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb602-7"><a href="mixed-models.html#cb602-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Systolic blood pressure (mmHg)&quot;</span>) <span class="sc">+</span> </span>
<span id="cb602-8"><a href="mixed-models.html#cb602-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> randid, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-305-1.png" width="672" /></p>
<p>It’s a bit subtle to see here, but unlike in our earlier model, now each
prediction (dashed line) has a slope that can vary between study subjects.
We can check this as well by running <code>coef</code>:</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="mixed-models.html#cb603-1" aria-hidden="true" tabindex="-1"></a>age_mm_mod2 <span class="sc">%&gt;%</span> </span>
<span id="cb603-2"><a href="mixed-models.html#cb603-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coef</span>()</span></code></pre></div>
<pre><code>## $randid
##         (Intercept)         age
## 11252     106.66493 0.586807745
## 984473     91.36055 1.005592509
## 1705869    74.78124 1.459263808
## 1778003    97.72449 0.831451282
## 2963281   119.12588 0.245829888
## 3071444   104.82388 0.637185863
## 4227351   127.97246 0.003754752
## 4452358    96.44882 0.866358574
## 7010106    96.65865 0.860616783
## 7112885   105.83536 0.609508034
## 7409622   104.87867 0.635686492
## 7434568    96.79621 0.856852485
## 8638285   102.53088 0.699930724
## 9356685    75.96414 1.426895303
## 9694232    96.81986 0.856205365
## 
## attr(,&quot;class&quot;)
## [1] &quot;coef.mer&quot;</code></pre>
<p>When we ran this function on the earlier model, we only got estimates for an
intercept for each study subject. Now we get subject-specific intercepts and
slopes for how blood pressure changes with age (or <span class="math inline">\(\beta_{1} + b_{1i}\)</span>). You
can see that, for some study subjects, this slope is very close to zero (i.e.,
blood pressure stays similar with age), while for others, it’s much higher than
the fixed effects estimate for the age slope of 0.72 from our earlier model.</p>
</div>
<div id="some-final-points-on-mixed-effects-models" class="section level2" number="9.5">
<h2><span class="header-section-number">9.5</span> Some final points on mixed effects models:</h2>
<ul>
<li>Fitting multiple levels of nesting (e.g., measures within people within families)</li>
</ul>
<p>As we’ve noted earlier clusters can be nested within other clusrters. For example
if we have repeated observations over time for participant <span class="math inline">\(i\)</span> and several participants
per family <span class="math inline">\(j\)</span>, then we expect to have correlation within person, as well as within
family. These type of data are also considered multi-level or hierarchical due to
the levels of correlation and the hierarchy in these levels. The lowest level (participant)
is nested within a higher level (family). We can account for this type of correlation
structure by fitting a multilevel or hierarchical model. For a similar estimation
as above (assume we have repeated blood pressure measurements at time-periods <span class="math inline">\(t\)</span>
for each participant <span class="math inline">\(i\)</span> and multiple participants within each family <span class="math inline">\(j\)</span>) this
would look something like</p>
<p><span class="math display">\[
Y_{tij} = \beta_{0} + b_{ij} + b_{j} + \epsilon_{tij} 
\]</span></p>
<p>where we now hove two random intercepts, one for each participant <span class="math inline">\(i\)</span> in the <span class="math inline">\(j^th\)</span>
family (<span class="math inline">\(b_{ij}\)</span>) and one for each family <span class="math inline">\(j\)</span> (<span class="math inline">\(b_{ij}\)</span>).</p>
<p>Another important level of clustering especially in environmental epidemiology is
space, where a lot of observations on exposure and outcomes are spatially correlated.
A hierarchical model in this situation could be one applying to data with multiple
observations (time-periods <span class="math inline">\(t\)</span>) per participant <span class="math inline">\(i\)</span> and multiple participants per
zip code <span class="math inline">\(j\)</span>. We have multiple observations over time nested within participant,
and participants nested within zip code.</p>
<ul>
<li>Other forms of GLMs as mixed models (logistic, Poisson)</li>
</ul>
<p>The examples above have been dealing with a continuous outcome and the models we
were fitting were mixed effects linear models, however the mixed effects models
framework extends to the generilized linear model framework (generilized linear
mixed models). The <code>glmer</code> package in R allows for fitting of such models (e.g. 
Poisson, logistic etc) in a similar fashion to <code>lme4</code>. An intercept only + random
intercept per participant logistic model for repeated measures of a binary obesity variable (BMI&gt;30) would look like
<span class="math display">\[
logit(Pr[Y_{ti}=1]) = \beta_{0} + b_{i} 
\]</span></p>
<ul>
<li>GEEs as an alternative to mixed models</li>
</ul>
<p>Generalized estimating equations (GEEs) are an alternative approach to mixed models
in the case of repeated measures (or any clustered data). The GEE framework is a
population average model that avoids making any distributional assumptions on the
outcome, or specifying any particular covariance structure which makes GEEs an attractive
option. However, the interpetation of the findings from such models does not extend
to the individual level (again these are population average models), whereas we
saw how we got varying individual level predictions from our mixed models above (albeit
at the expense of further assumptions). The <code>geepack</code> package in R allows for fitting
of GEEs for clustered continuous and categorical data.</p>
<!--Other R packages for fitting mixed models (including Bayesian approaches)
Correlation structures that take account of time (for example, AR(1)) -->

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-block2011proximity" class="csl-entry">
Block, Jason P, Nicholas A Christakis, A James O’malley, and SV Subramanian. 2011. <span>“Proximity to Food Establishments and Body Mass Index in the Framingham Heart Study Offspring Cohort over 30 Years.”</span> <em>American Journal of Epidemiology</em> 174 (10): 1108–14.
</div>
<div id="ref-gelman2006data" class="csl-entry">
Gelman, Andrew, and Jennifer Hill. 2006. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. Cambridge university press.
</div>
<div id="ref-gibbons2010advances" class="csl-entry">
Gibbons, Robert D, Donald Hedeker, and Stephen DuToit. 2010. <span>“Advances in Analysis of Longitudinal Data.”</span> <em>Annual Review of Clinical Psychology</em> 6: 79–107.
</div>
<div id="ref-loucks2011associations" class="csl-entry">
Loucks, Eric B, Michal Abrahamowicz, Yongling Xiao, and John W Lynch. 2011. <span>“Associations of Education with 30 Year Life Course Blood Pressure Trajectories: Framingham Offspring Study.”</span> <em>BMC Public Health</em> 11 (1): 1–10.
</div>
<div id="ref-rice2013short" class="csl-entry">
Rice, Mary B, Petter L Ljungman, Elissa H Wilker, Diane R Gold, Joel D Schwartz, Petros Koutrakis, George R Washko, George T O’Connor, and Murray A Mittleman. 2013. <span>“Short-Term Exposure to Air Pollution and Lung Function in the Framingham Heart Study.”</span> <em>American Journal of Respiratory and Critical Care Medicine</em> 188 (11): 1351–57.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="some-approaches-for-confounding.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="instrumental-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["adv_epi_analysis.pdf", "adv_epi_analysis.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
