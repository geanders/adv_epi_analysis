<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Some approaches for confounding | Advanced Epidemiological Analysis</title>
  <meta name="description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Some approaches for confounding | Advanced Epidemiological Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Some approaches for confounding | Advanced Epidemiological Analysis" />
  
  <meta name="twitter:description" content="This is the coursebook for the Colorado State University course ERHS 732, Advanced Epidemiological Analysis." />
  

<meta name="author" content="Andreas M. Neophytou and G. Brooke Anderson" />


<meta name="date" content="2021-10-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="longitudinal-cohort-study-designs.html"/>
<link rel="next" href="mixed-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Advanced Epidemiological Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Overview</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i><b>1.1</b> License</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="courseinfo.html"><a href="courseinfo.html"><i class="fa fa-check"></i><b>2</b> Course information</a><ul>
<li class="chapter" data-level="2.1" data-path="courseinfo.html"><a href="courseinfo.html#course-learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Course learning objectives</a></li>
<li class="chapter" data-level="2.2" data-path="courseinfo.html"><a href="courseinfo.html#meeting-time-and-place"><i class="fa fa-check"></i><b>2.2</b> Meeting time and place</a></li>
<li class="chapter" data-level="2.3" data-path="courseinfo.html"><a href="courseinfo.html#class-structure-and-expectations"><i class="fa fa-check"></i><b>2.3</b> Class Structure and Expectations</a></li>
<li class="chapter" data-level="2.4" data-path="courseinfo.html"><a href="courseinfo.html#course-grading"><i class="fa fa-check"></i><b>2.4</b> Course grading</a></li>
<li class="chapter" data-level="2.5" data-path="courseinfo.html"><a href="courseinfo.html#course-schedule"><i class="fa fa-check"></i><b>2.5</b> Course Schedule</a></li>
<li class="chapter" data-level="2.6" data-path="courseinfo.html"><a href="courseinfo.html#textbooks-and-course-materials"><i class="fa fa-check"></i><b>2.6</b> Textbooks and Course Materials</a></li>
<li class="chapter" data-level="2.7" data-path="courseinfo.html"><a href="courseinfo.html#prerequisites-and-preparation"><i class="fa fa-check"></i><b>2.7</b> Prerequisites and Preparation</a></li>
<li class="chapter" data-level="2.8" data-path="courseinfo.html"><a href="courseinfo.html#academic-honesty"><i class="fa fa-check"></i><b>2.8</b> Academic Honesty</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html"><i class="fa fa-check"></i><b>3</b> Time series / case-crossover studies</a><ul>
<li class="chapter" data-level="3.1" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#readings"><i class="fa fa-check"></i><b>3.1</b> Readings</a></li>
<li class="chapter" data-level="3.2" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#time-series-and-case-crossover-study-designs"><i class="fa fa-check"></i><b>3.2</b> Time series and case-crossover study designs</a></li>
<li class="chapter" data-level="3.3" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#time-series-data"><i class="fa fa-check"></i><b>3.3</b> Time series data</a></li>
<li class="chapter" data-level="3.4" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>3.4</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="3.5" data-path="time-series-case-crossover-studies.html"><a href="time-series-case-crossover-studies.html#statistical-modeling-for-a-time-series-study"><i class="fa fa-check"></i><b>3.5</b> Statistical modeling for a time series study</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>4</b> Generalized linear models</a><ul>
<li class="chapter" data-level="4.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#readings-1"><i class="fa fa-check"></i><b>4.1</b> Readings</a></li>
<li class="chapter" data-level="4.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#splines-in-glms"><i class="fa fa-check"></i><b>4.2</b> Splines in GLMs</a></li>
<li class="chapter" data-level="4.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#distributed-lags-and-cross-basis-functions-in-glms"><i class="fa fa-check"></i><b>4.3</b> Distributed lags and cross-basis functions in GLMs</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="natural-experiments.html"><a href="natural-experiments.html"><i class="fa fa-check"></i><b>5</b> Natural experiments</a><ul>
<li class="chapter" data-level="5.1" data-path="natural-experiments.html"><a href="natural-experiments.html#readings-2"><i class="fa fa-check"></i><b>5.1</b> Readings</a></li>
<li class="chapter" data-level="5.2" data-path="natural-experiments.html"><a href="natural-experiments.html#natural-experiments-1"><i class="fa fa-check"></i><b>5.2</b> Natural experiments</a></li>
<li class="chapter" data-level="5.3" data-path="natural-experiments.html"><a href="natural-experiments.html#interrupted-time-series"><i class="fa fa-check"></i><b>5.3</b> Interrupted time series</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html"><i class="fa fa-check"></i><b>6</b> Estimating health impacts</a><ul>
<li class="chapter" data-level="6.1" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html#readings-3"><i class="fa fa-check"></i><b>6.1</b> Readings</a></li>
<li class="chapter" data-level="6.2" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html#attributable-risk-and-attributable-number"><i class="fa fa-check"></i><b>6.2</b> Attributable risk and attributable number</a></li>
<li class="chapter" data-level="6.3" data-path="estimating-health-impacts.html"><a href="estimating-health-impacts.html#quantifying-potential-health-impacts-under-different-scenarios"><i class="fa fa-check"></i><b>6.3</b> Quantifying potential health impacts under different scenarios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html"><i class="fa fa-check"></i><b>7</b> Longitudinal cohort study designs</a><ul>
<li class="chapter" data-level="7.1" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#readings-4"><i class="fa fa-check"></i><b>7.1</b> Readings</a></li>
<li class="chapter" data-level="7.2" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#longitudinal-cohort-data"><i class="fa fa-check"></i><b>7.2</b> Longitudinal cohort data</a></li>
<li class="chapter" data-level="7.3" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#coding-a-survival-analysis"><i class="fa fa-check"></i><b>7.3</b> Coding a survival analysis</a></li>
<li class="chapter" data-level="7.4" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#handling-complexity"><i class="fa fa-check"></i><b>7.4</b> Handling complexity</a><ul>
<li class="chapter" data-level="7.4.1" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#recurrent-outcome-and-time-varying-exposures"><i class="fa fa-check"></i><b>7.4.1</b> Recurrent outcome and time varying-exposures</a></li>
<li class="chapter" data-level="7.4.2" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#multi-level-exposure"><i class="fa fa-check"></i><b>7.4.2</b> Multi-level exposure</a></li>
<li class="chapter" data-level="7.4.3" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#time-varying-coefficients"><i class="fa fa-check"></i><b>7.4.3</b> Time-varying coefficients</a></li>
<li class="chapter" data-level="7.4.4" data-path="longitudinal-cohort-study-designs.html"><a href="longitudinal-cohort-study-designs.html#using-survey-data-e.g.-nhanes"><i class="fa fa-check"></i><b>7.4.4</b> Using survey data (e.g. NHANES)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html"><i class="fa fa-check"></i><b>8</b> Some approaches for confounding</a><ul>
<li class="chapter" data-level="8.1" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#readings-5"><i class="fa fa-check"></i><b>8.1</b> Readings</a></li>
<li class="chapter" data-level="8.2" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#inverse-probability-weighting"><i class="fa fa-check"></i><b>8.2</b> Inverse probability weighting</a></li>
<li class="chapter" data-level="8.3" data-path="some-approaches-for-confounding.html"><a href="some-approaches-for-confounding.html#propensity-scores"><i class="fa fa-check"></i><b>8.3</b> Propensity scores</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>9</b> Mixed models</a></li>
<li class="chapter" data-level="10" data-path="instrumental-variables.html"><a href="instrumental-variables.html"><i class="fa fa-check"></i><b>10</b> Instrumental variables</a></li>
<li class="chapter" data-level="11" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>11</b> Causal inference</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Epidemiological Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="some-approaches-for-confounding" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Some approaches for confounding</h1>
<div id="readings-5" class="section level2">
<h2><span class="header-section-number">8.1</span> Readings</h2>
<p>The required readings for this chapter are:</p>
<ul>
<li><p><span class="citation">Hernán and Robins (<a href="#ref-hernanch12" role="doc-biblioref">2020</a><a href="#ref-hernanch12" role="doc-biblioref">a</a>)</span>: IP weighting for confounding adjustment and the concept of a Marginal Structural Model</p></li>
<li><p><span class="citation">Hernán and Robins (<a href="#ref-hernanch15" role="doc-biblioref">2020</a><a href="#ref-hernanch15" role="doc-biblioref">b</a>)</span>: Propensity scores and outcome regression</p></li>
</ul>
<p>There are also some supplemental readings you may find useful:
The following is an instructional paper on constructing IP weights for marginal structural models:</p>
<ul>
<li><span class="citation">Cole and Hernán (<a href="#ref-cole2008constructing" role="doc-biblioref">2008</a>)</span></li>
</ul>
<p>This paper describes the use of propensity scores as an umbrella term for these types of approaches for covariate adjustment:</p>
<ul>
<li><span class="citation">Brookhart et al. (<a href="#ref-brookhart2013propensity" role="doc-biblioref">2013</a>)</span></li>
</ul>
<p>The following papers comment on the use of machine learning to improve or propensity score/weight estimation</p>
<ul>
<li><p><span class="citation">Lee, Lessler, and Stuart (<a href="#ref-lee2010improving" role="doc-biblioref">2010</a>)</span></p></li>
<li><p><span class="citation">Westreich, Lessler, and Funk (<a href="#ref-westreich2010propensity" role="doc-biblioref">2010</a>)</span></p></li>
</ul>
<p>while this chapter of the causal inference book explains the problem with traditional regression and exposure-confounder feedback</p>
<ul>
<li><span class="citation">Hernán and Robins (<a href="#ref-hernanch20" role="doc-biblioref">2020</a><a href="#ref-hernanch20" role="doc-biblioref">c</a>)</span></li>
</ul>
<p>Lastly this paper offers a very good explanation on (non-)collapsibility:</p>
<ul>
<li><span class="citation">Greenland, Pearl, and Robins (<a href="#ref-greenland1999confounding" role="doc-biblioref">1999</a>)</span></li>
</ul>
</div>
<div id="inverse-probability-weighting" class="section level2">
<h2><span class="header-section-number">8.2</span> Inverse probability weighting</h2>
<p>We’ve already fit some Cox models with multiple covariates, where the interpretation of each parameter coefficient is <em>conditional</em> on the other parameters in the model, and typically these coefficients are expected to yield effect estimates unconfounded by the other variables in the model. In this section we will explore an alternative approach to confounding adjustment in inverse probability weighting (IPW).</p>
<p><em>Applied exercise: IPW for confounding adjustment</em></p>
<p>Using the FHS cohort data answer the following questions with repect to confounding of the potential effect of smoking on mortality and incident MI hospitalizations:</p>
<ol style="list-style-type: decimal">
<li>Fit a conditional Cox model for the effect of smoking on mortality adjusting for sex and age using the limited (one observation per participant). Estimate inverse probability weights for smoking exposure and fit a Marginal Structural Cox model using the weighted population. How do the results of the two models compare?</li>
<li>Plot survival curves for mortality and smoking status in the unweighted and weighted population. How do those curves compare?</li>
<li>Using the time-varying dataset fit a conditional Cox model for smoking and MI hospitalizations adjusting for age, sex, BMI and blood pressure. Estimate time-varying inverse probability weights for exposure and fit a Marginal Structural Cox Model. How do the results of those two models compare?</li>
</ol>
<p>Based on this exploratory exercise, think about what each approach is doing in terms of adjusting for confounding, and pros and cons for each in each situation.</p>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>Fit a conditional Cox model for the effec of smoking on mortality adjusting for sex and age. Estimate inverse probability weights for smoking exposure and fit a Marginal Structural Cox model using the weighted population. How do the results of the two models compare?</strong></li>
</ol>
<p>Let’s look back at our FHS data and reconstruct our simple models for current smoking status first unadjusted and then with age and sex also in the model.</p>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.43   1.19    1.73</code></pre>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.35   1.11    1.64</code></pre>
<p>The first model simply compares current smokers to current non-smokers in the population. It is not conditional on other variables, but also not adjusted for any potential confoudning by them. The interpretation of the (exponentiated) parameter for <code>cursmoke</code> in the adjusted model, is the Hazard Ratio comparing current smokers to current non-smokers <em>conditional</em> on age and sex. In other words this is the log-Hazard Ratio comparing currently smoking males of the same age to currently non-smoking males of the same age, and similarly currently smoking females of the same age to currently non-smoking females of the same age. This <em>conditioning</em> on other variables by including them in a regression model is often sufficient to adjust for any confounding by these variables and is the most widely used approach to adjust for confounding. In this example we see a much higher HR in the adjusted (conditional) model than the unadjusted.</p>
<p>One alternative approach to this is <em>inverse probability weighting</em> or IPW. IPW allows us to adjust for confounding without having to include additional variables in out final outcome model other than the exposure of interest. Instead we weigh each participant by the inverse of the probability that they had the exposure value they indeed had conditional on these other (potentially confounding variables). The quantity we are estimating is:
<span class="math display">\[
W=\frac{1}{f[X|V]}
\]</span>
where <span class="math inline">\(X\)</span> is the exposure of interest and <span class="math inline">\(V\)</span> is a vector for baseline confounders in this case age and sex.
Typically the weight estimation will involve a model for the exposure conditional on the potential confounders. Let’s go ahead and do this weight estimation for the above example using the <code>fhs_first</code> subset of the data. We will fit a logistic model for <code>cursmoke</code> conditional on age and sex which we will use to get predictions for the conditional probabilit of exposure:</p>
<div class="sourceCode" id="cb489"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb489-1"><a href="some-approaches-for-confounding.html#cb489-1"></a>model_IPW&lt;-<span class="kw">glm</span>(cursmoke<span class="op">~+</span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">family=</span><span class="st">&#39;binomial&#39;</span>, <span class="dt">data=</span>fhs_first)</span>
<span id="cb489-2"><a href="some-approaches-for-confounding.html#cb489-2"></a>model_IPW <span class="op">%&gt;%</span></span>
<span id="cb489-3"><a href="some-approaches-for-confounding.html#cb489-3"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 3 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   3.84     0.218        17.6 1.37e-69
## 2 age          -0.0514   0.00370     -13.9 8.06e-44
## 3 sex          -0.839    0.0634      -13.2 6.04e-40</code></pre>
<p>We can see that these variables are significantly associated with current smoking status, however we are not going to be interpreting the parameter coefficients from this model. Instead, we will be using predictions based on this model to estimate our inverse probability weights:</p>
<div class="sourceCode" id="cb491"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb491-1"><a href="some-approaches-for-confounding.html#cb491-1"></a>fhs_first &lt;-fhs_first <span class="op">%&gt;%</span></span>
<span id="cb491-2"><a href="some-approaches-for-confounding.html#cb491-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_smokobs=</span><span class="kw">ifelse</span>(cursmoke <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,   <span class="co">###estimate the conditional probability that someone is unexposed or exposed from the model above</span></span>
<span id="cb491-3"><a href="some-approaches-for-confounding.html#cb491-3"></a>         <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(model_IPW, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb491-4"><a href="some-approaches-for-confounding.html#cb491-4"></a>         <span class="kw">predict</span>(model_IPW, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)),</span>
<span id="cb491-5"><a href="some-approaches-for-confounding.html#cb491-5"></a>         <span class="dt">w=</span><span class="dv">1</span><span class="op">/</span>p_smokobs)<span class="co">#### The weights is the inverse of the probability of exposure value</span></span>
<span id="cb491-6"><a href="some-approaches-for-confounding.html#cb491-6"></a></span>
<span id="cb491-7"><a href="some-approaches-for-confounding.html#cb491-7"></a>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb491-8"><a href="some-approaches-for-confounding.html#cb491-8"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_w=</span><span class="kw">mean</span>(w),</span>
<span id="cb491-9"><a href="some-approaches-for-confounding.html#cb491-9"></a>            <span class="dt">max_w=</span><span class="kw">max</span>(w),</span>
<span id="cb491-10"><a href="some-approaches-for-confounding.html#cb491-10"></a>            <span class="dt">min_w=</span><span class="kw">min</span>(w),</span>
<span id="cb491-11"><a href="some-approaches-for-confounding.html#cb491-11"></a>            <span class="dt">sum_w=</span><span class="kw">sum</span>(w))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   mean_w max_w min_w sum_w
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   2.00  4.79  1.24 8871.</code></pre>
<p>The mean weight value is 2, so by using the weights we’ll on average be using 2 copies of each participant. Accordingly, the total sum of the weights is 8870 which is roughly double the number of participants we started with. This is because what the weights are doing in this example, is basically create a pseudopopulation where we have enough people so that everyone can be both exposed and unexposed while maintaining the distribution of covariates (here age and sex). The latter has to hold, because the pseudopopulation has to be representative of the original target population. We can check this by looking at the distributions of age sex in both the weighted and unweighted data.</p>
<div class="sourceCode" id="cb493"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb493-1"><a href="some-approaches-for-confounding.html#cb493-1"></a>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb493-2"><a href="some-approaches-for-confounding.html#cb493-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_age=</span><span class="kw">mean</span>(age),</span>
<span id="cb493-3"><a href="some-approaches-for-confounding.html#cb493-3"></a>            <span class="dt">mean_agew=</span>(<span class="kw">sum</span>(age<span class="op">*</span>w)<span class="op">/</span><span class="kw">sum</span>(w)))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##   mean_age mean_agew
##      &lt;dbl&gt;     &lt;dbl&gt;
## 1     49.9      49.7</code></pre>
<div class="sourceCode" id="cb495"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb495-1"><a href="some-approaches-for-confounding.html#cb495-1"></a>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb495-2"><a href="some-approaches-for-confounding.html#cb495-2"></a><span class="st">  </span><span class="kw">filter</span>(sex<span class="op">==</span><span class="dv">2</span>) <span class="op">%&gt;%</span></span>
<span id="cb495-3"><a href="some-approaches-for-confounding.html#cb495-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">femalecount =</span> <span class="kw">n</span>(),</span>
<span id="cb495-4"><a href="some-approaches-for-confounding.html#cb495-4"></a>            <span class="dt">femalecountw =</span> <span class="kw">sum</span>(w))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 2
##   femalecount femalecountw
##         &lt;int&gt;        &lt;dbl&gt;
## 1        2490        4918.</code></pre>
<p>We see that the mean age is very similar in the original sample and in the pseudopopulation, while the number of females roughly doubles (as does the whole population), therefore approximately maintaining the initial proportion of females.</p>
<p>The great thing about the pseudopopulation is that the effect of <code>cursmoke</code> in no longer confounded by age and sex.
We can go ahead and fit a Cox proportional hazards model for <code>cursmoke</code> using our weights, and without including age and sex in the model.</p>
<div class="sourceCode" id="cb497"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb497-1"><a href="some-approaches-for-confounding.html#cb497-1"></a><span class="co">###Fit Cox weighted model for current smoking status</span></span>
<span id="cb497-2"><a href="some-approaches-for-confounding.html#cb497-2"></a>coxph_modIPW&lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timedth, death) <span class="op">~</span><span class="st"> </span>cursmoke, <span class="dt">weights=</span>w,</span>
<span id="cb497-3"><a href="some-approaches-for-confounding.html#cb497-3"></a>                    <span class="dt">data =</span> fhs_first)</span>
<span id="cb497-4"><a href="some-approaches-for-confounding.html#cb497-4"></a>coxph_modIPW <span class="op">%&gt;%</span></span>
<span id="cb497-5"><a href="some-approaches-for-confounding.html#cb497-5"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 1 × 6
##   term     estimate std.error robust.se statistic       p.value
##   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 cursmoke    0.313    0.0363    0.0532      5.88 0.00000000412</code></pre>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="some-approaches-for-confounding.html#cb499-1"></a>coxph_modIPW <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb499-2"><a href="some-approaches-for-confounding.html#cb499-2"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb499-3"><a href="some-approaches-for-confounding.html#cb499-3"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb499-4"><a href="some-approaches-for-confounding.html#cb499-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb499-5"><a href="some-approaches-for-confounding.html#cb499-5"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb499-6"><a href="some-approaches-for-confounding.html#cb499-6"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb499-7"><a href="some-approaches-for-confounding.html#cb499-7"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb499-8"><a href="some-approaches-for-confounding.html#cb499-8"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb499-9"><a href="some-approaches-for-confounding.html#cb499-9"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.37   1.27    1.47</code></pre>
<p>We see that the HR is very similar to before (they are not exaclty the same because of the non-collapsibility of the HR, more on this below). We also see that the CIs are actually narrower. This is because we are now using the pseudopopulation which is twice the number of the original population. A larger sample size means more power and by extension smaller standard errors, but in our case this larger sample size is artificial, not real and our CIs are misleadingly narrow. Rather than rely on the stanard erros from the model, we instead have to rely on robust variance estimators that counteract our artificially inflated sample size. We can do this, by using generalized estimation equations for clustered (correlated data). Our data are considered clustered, because of the multiple copies for each participant (<code>randid</code>). If we repeat the above model with a <code>cluster</code> term for <code>randid</code> this will invoke a robust sandwich variance estimation.</p>
<p>We mentioned that the HR is non-collapsible. What this means is that a conditional estimate of the HR for an exposure of interes within levels of another predictor of the outcome is not collapsible as a marginal estimate (over all levels of the predictors) even in the absence of confoudning. In other words if age was a predictor of the outcome (mortality increases with increasing age), but was not associated with the smoking, we would still expect the HR for smoking to change after adjusting for age (here it would be higher). Therefore in our example where age is in fact a confounder, even if we assume that our MSM based HR takes care of all confounding by age, we still don’t necessarily expect it to be the same as the conditional HR from the model controlling for age due to non-collapsibility of the HR. Non-collapsibility is a property of parameters based on the hazard, rate and odds, but not the risk. See the paper by <span class="citation">(Greenland, Pearl, and Robins <a href="#ref-greenland1999confounding" role="doc-biblioref">1999</a>)</span> for more on collapsibility.</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="some-approaches-for-confounding.html#cb501-1"></a>coxph_modIPW&lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timedth, death) <span class="op">~</span><span class="st"> </span>cursmoke, <span class="dt">weights=</span>w, <span class="dt">cluster =</span> randid,</span>
<span id="cb501-2"><a href="some-approaches-for-confounding.html#cb501-2"></a>                    <span class="dt">data =</span> fhs_first)</span>
<span id="cb501-3"><a href="some-approaches-for-confounding.html#cb501-3"></a>coxph_modIPW <span class="op">%&gt;%</span></span>
<span id="cb501-4"><a href="some-approaches-for-confounding.html#cb501-4"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 1 × 6
##   term     estimate std.error robust.se statistic       p.value
##   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;
## 1 cursmoke    0.313    0.0363    0.0532      5.88 0.00000000412</code></pre>
<p>We now have to use the <code>robust.se</code> rather than <code>std.error</code> to construct our CIs:</p>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="some-approaches-for-confounding.html#cb503-1"></a>coxph_modIPW <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb503-2"><a href="some-approaches-for-confounding.html#cb503-2"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb503-3"><a href="some-approaches-for-confounding.html#cb503-3"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb503-4"><a href="some-approaches-for-confounding.html#cb503-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb503-5"><a href="some-approaches-for-confounding.html#cb503-5"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>robust.se, </span>
<span id="cb503-6"><a href="some-approaches-for-confounding.html#cb503-6"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>robust.se, </span>
<span id="cb503-7"><a href="some-approaches-for-confounding.html#cb503-7"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb503-8"><a href="some-approaches-for-confounding.html#cb503-8"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb503-9"><a href="some-approaches-for-confounding.html#cb503-9"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.37   1.23    1.52</code></pre>
<p>The CIs are now wider than before and more akin to the width of the CIs from the original conditional model. This weighted model is essentially a Marginal Structural Cox Model. Marginal Structural Models (MSMs) refer to models that are <em>marginal</em> or <em>unconditional</em> with respect to some covariates, as is the case of our model with respect to age and sex. The interpretaton for the Cox MSM hazard ratios is no longer conditional on age and sex or in other words we are not looking for effects within levels of age and sex. We are however still adjusting for confounding by these variables. It is also <em>structural</em> because we are essentially modeling counterfactuals (the result of the weights gives us enough participants so that everyone (from the original 4434 participants) can be exposed and unexposed). MSMs are essenctially considered causal models though the causal interpretation relies on several assumptions (exchangeability, consistency, positivity, no information bias, correct model specification). In our case if there exist more confounders other than age and sex (likely) then the exchangeability assumption fails.</p>
<p>The use of weights and introduction of a counterfactual framework also changes the interpretation of the HR from a mere comparison of smokers and non-smokers in the population to a comparison of what would happened if everyone in the population was a smoker to what would have happened if no one was a smoker.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Plot survival curves for mortality and smoking status in the unweighted and weighted population. How do those curves compare?</strong></li>
</ol>
<p>Using the weighted pseudopopulation we can also construct survival curves comparing what would happen if everyone had been a smoker and what would happen had no one smoked, that are inherenelty adjusted for any confounding by age and sex. We did fit survival curves comparing smokers and non-smokers in the unweighted data that were unadjusted in 7.3:</p>
<div class="sourceCode" id="cb505"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb505-1"><a href="some-approaches-for-confounding.html#cb505-1"></a>fit_smoke &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(timedthy, death) <span class="op">~</span><span class="st"> </span>cursmoke, <span class="dt">data =</span> fhs_first)</span>
<span id="cb505-2"><a href="some-approaches-for-confounding.html#cb505-2"></a>fit_smoke <span class="op">%&gt;%</span></span>
<span id="cb505-3"><a href="some-approaches-for-confounding.html#cb505-3"></a><span class="st">  </span><span class="kw">ggsurvplot</span>(<span class="dt">xlab =</span> <span class="st">&quot;Time to death (years)&quot;</span>,</span>
<span id="cb505-4"><a href="some-approaches-for-confounding.html#cb505-4"></a>             <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Overall Survival Probablity &#39;</span>, </span>
<span id="cb505-5"><a href="some-approaches-for-confounding.html#cb505-5"></a>                                     <span class="kw">hat</span>(S)<span class="op">*</span><span class="st">&quot;(t)&quot;</span>)))</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-257-1.png" width="672" /></p>
<p>In the weighted pseudopopulation:</p>
<div class="sourceCode" id="cb506"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb506-1"><a href="some-approaches-for-confounding.html#cb506-1"></a>fit_smokeW &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(timedthy, death) <span class="op">~</span><span class="st"> </span>cursmoke, <span class="dt">weights=</span>w, <span class="dt">data =</span> fhs_first)</span>
<span id="cb506-2"><a href="some-approaches-for-confounding.html#cb506-2"></a>fit_smokeW <span class="op">%&gt;%</span></span>
<span id="cb506-3"><a href="some-approaches-for-confounding.html#cb506-3"></a><span class="st">  </span><span class="kw">ggsurvplot</span>(<span class="dt">xlab =</span> <span class="st">&quot;Time to death (years)&quot;</span>,</span>
<span id="cb506-4"><a href="some-approaches-for-confounding.html#cb506-4"></a>             <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&#39;Overall Survival Probablity &#39;</span>, </span>
<span id="cb506-5"><a href="some-approaches-for-confounding.html#cb506-5"></a>                                     <span class="kw">hat</span>(S)<span class="op">*</span><span class="st">&quot;(t)&quot;</span>)))</span></code></pre></div>
<p><img src="adv_epi_analysis_files/figure-html/unnamed-chunk-258-1.png" width="672" /></p>
<p>We see that there is a difference in the two plots, with the smokers and non-smokers having quite similar survival curves in the first one, but a separation in the second one that again in inherently adjusted for confounding by sex and age.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Using the time-varying dataset fit a conditional Cox model for smoking and MI hospitalizations adjusting for age, sex, BMI and blood pressure. Estimate time-varying inverse probability weights for exposure and fit a Marginal Structural Cox Model. How do the results of those two models compare?</strong></li>
</ol>
<p>Now let’s revisit the time-varying dataset we created and fit a conditional model for time-varying smoking status and MI hospitalization adjusted for age, sex, BMI and systolic blood pressure.</p>
<div class="sourceCode" id="cb507"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb507-1"><a href="some-approaches-for-confounding.html#cb507-1"></a>coxph_modtvMI &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(time, timemi2, hospmitv) <span class="op">~</span><span class="st"> </span></span>
<span id="cb507-2"><a href="some-approaches-for-confounding.html#cb507-2"></a><span class="st">                                </span>cursmoke <span class="op">+</span><span class="st"> </span><span class="kw">ns</span>(bmi, <span class="dt">df =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ns</span>(sysbp, <span class="dt">df =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb507-3"><a href="some-approaches-for-confounding.html#cb507-3"></a><span class="st">                                </span>age <span class="op">+</span><span class="st"> </span>sex, </span>
<span id="cb507-4"><a href="some-approaches-for-confounding.html#cb507-4"></a>                              <span class="dt">data =</span> fhstv_incMI)</span>
<span id="cb507-5"><a href="some-approaches-for-confounding.html#cb507-5"></a>coxph_modtvMI <span class="op">%&gt;%</span></span>
<span id="cb507-6"><a href="some-approaches-for-confounding.html#cb507-6"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 9 × 5
##   term               estimate std.error statistic  p.value
##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 cursmoke             0.588    0.109       5.40  6.77e- 8
## 2 ns(bmi, df = 3)1     0.942    0.391       2.41  1.59e- 2
## 3 ns(bmi, df = 3)2     0.241    1.57        0.154 8.78e- 1
## 4 ns(bmi, df = 3)3    -0.377    1.43       -0.263 7.92e- 1
## 5 ns(sysbp, df = 3)1   2.06     0.414       4.97  6.67e- 7
## 6 ns(sysbp, df = 3)2   4.85     1.62        2.98  2.84e- 3
## 7 ns(sysbp, df = 3)3   3.77     1.05        3.59  3.30e- 4
## 8 age                  0.0322   0.00655     4.92  8.60e- 7
## 9 sex                 -1.15     0.114     -10.1   3.43e-24</code></pre>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="some-approaches-for-confounding.html#cb509-1"></a>coxph_modtvMI <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb509-2"><a href="some-approaches-for-confounding.html#cb509-2"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb509-3"><a href="some-approaches-for-confounding.html#cb509-3"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &#39;cursmoke&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb509-4"><a href="some-approaches-for-confounding.html#cb509-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb509-5"><a href="some-approaches-for-confounding.html#cb509-5"></a>         <span class="dt">low_ci =</span> (estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error), </span>
<span id="cb509-6"><a href="some-approaches-for-confounding.html#cb509-6"></a>         <span class="dt">high_ci =</span> (estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error), </span>
<span id="cb509-7"><a href="some-approaches-for-confounding.html#cb509-7"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb509-8"><a href="some-approaches-for-confounding.html#cb509-8"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb509-9"><a href="some-approaches-for-confounding.html#cb509-9"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.80   1.45    2.23</code></pre>
<p>One concern from this model is that BMI and systolic blood pressure maybe mediators for the effect of smoking on MI hospitalizations, in which case we wouldn’t want to control for them. However, given the time-varying nature of the exposure, BMI and systolic blood pressure may also be confounders if they have an effect on who changes smoking status in the future. This creates an exposure-confounder feedback, with the confounder causing the exposure and the exposure in turn having an effect on the confounder a later time point. Traditional regression approaches are not adequately equipped to handle this type of confounding, however IPW (and some other approaches) can adjust for confounding without blocking any mediating pathways.</p>
<p>In this time-varying setting the inverse probability weights will also be time-varying and the quantity is
<span class="math display">\[
W=\prod_{t}\frac{1}{f[X_{t}|\bar{X}_{t-1},\bar{C}_{t-1},V]}
\]</span>
where at each time point (period) the weight is the cumulative product of the inverse of the probability of the exposure value at each time point <span class="math inline">\(X_{t}\)</span> conditional on the history of past exposures <span class="math inline">\(\bar{X}_{t-1}\)</span> and covariates <span class="math inline">\(\bar{C}_{t-1}\)</span> up to the previous period as well as the baseline covariates. In our case the time varying covariates <span class="math inline">\(C_{t}\)</span> are BMI and systolic blood pressure, while baseline covariates <span class="math inline">\(V\)</span> are age and sex.</p>
<p>In order to estimate these weights we would have to lag exposure, BMI and systolic blood pressure in order to predict current exposure <span class="math inline">\(X_{t}\)</span> using past exposure and covariate values <span class="math inline">\(X_{t-1}\)</span> and <span class="math inline">\(C_{t-1}\)</span>. We are omitting the overbars denoting history as we will assume the most recent value from the past is adequate to represent exposure and coviariate histories.</p>
<div class="sourceCode" id="cb511"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb511-1"><a href="some-approaches-for-confounding.html#cb511-1"></a>fhstv_incMI&lt;-fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb511-2"><a href="some-approaches-for-confounding.html#cb511-2"></a><span class="st">  </span><span class="kw">group_by</span>(randid) <span class="op">%&gt;%</span></span>
<span id="cb511-3"><a href="some-approaches-for-confounding.html#cb511-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">cursmoke_l1=</span><span class="kw">lag</span>(cursmoke),</span>
<span id="cb511-4"><a href="some-approaches-for-confounding.html#cb511-4"></a>         <span class="dt">cursmoke_l1=</span><span class="kw">ifelse</span>(period<span class="op">==</span><span class="dv">1</span>, cursmoke, cursmoke_l1), <span class="co">###we are setting the lagged smoking status variable to equal the present smoking status value (we are assuming smoking status didn&#39;t change right at the beginning of follow-up)</span></span>
<span id="cb511-5"><a href="some-approaches-for-confounding.html#cb511-5"></a>         <span class="dt">bmi_l1=</span><span class="kw">lag</span>(bmi),</span>
<span id="cb511-6"><a href="some-approaches-for-confounding.html#cb511-6"></a>         <span class="dt">bmi_l1=</span><span class="kw">ifelse</span>(period<span class="op">==</span><span class="dv">1</span>, <span class="dv">0</span>, bmi_l1),</span>
<span id="cb511-7"><a href="some-approaches-for-confounding.html#cb511-7"></a>         <span class="dt">sysbp_l1=</span><span class="kw">lag</span>(sysbp),</span>
<span id="cb511-8"><a href="some-approaches-for-confounding.html#cb511-8"></a>         <span class="dt">sysbp_l1=</span><span class="kw">ifelse</span>(period<span class="op">==</span><span class="dv">1</span>, <span class="dv">0</span>, sysbp_l1)) <span class="op">%&gt;%</span></span>
<span id="cb511-9"><a href="some-approaches-for-confounding.html#cb511-9"></a><span class="st">  </span><span class="kw">ungroup</span>()</span></code></pre></div>
<p>Furthermore as we are assuming an order where smoking is a cause of BMI and systolic blood pressure at each time period, we don’t have BMI and blood pressure values to predict exposure at period 1. We have set those to zero above, so we can actually get a prediction for the probability of exposure values at this period based on the baseline variables values. We will also inclue time in the model, as in this time-varying setting it’s safe to assume that time-varying variables are a function of time.</p>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="some-approaches-for-confounding.html#cb512-1"></a>mod_tvIPW&lt;-<span class="kw">glm</span>(cursmoke<span class="op">~</span><span class="kw">ns</span>(time, <span class="dt">df=</span><span class="dv">2</span>)<span class="op">+</span>age<span class="op">+</span>sex<span class="op">+</span>cursmoke_l1 <span class="op">+</span><span class="st"> </span><span class="kw">ns</span>(bmi_l1, <span class="dt">df=</span><span class="dv">2</span>)<span class="op">+</span>sysbp_l1, <span class="dt">family=</span>binomial, <span class="dt">data=</span>fhstv_incMI)</span>
<span id="cb512-2"><a href="some-approaches-for-confounding.html#cb512-2"></a>mod_tvIPW <span class="op">%&gt;%</span></span>
<span id="cb512-3"><a href="some-approaches-for-confounding.html#cb512-3"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 9 × 5
##   term                estimate std.error statistic  p.value
##   &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)         -1.09      0.288      -3.80  1.47e- 4
## 2 ns(time, df = 2)1    1.14      2.22        0.515 6.06e- 1
## 3 ns(time, df = 2)2   -0.690     0.421      -1.64  1.01e- 1
## 4 age                 -0.0368    0.00484    -7.62  2.59e-14
## 5 sex                  0.0273    0.0791      0.346 7.30e- 1
## 6 cursmoke_l1          5.72      0.0979     58.4   0       
## 7 ns(bmi_l1, df = 2)1 -2.97      1.88       -1.58  1.13e- 1
## 8 ns(bmi_l1, df = 2)2 -2.22      0.868      -2.56  1.06e- 2
## 9 sysbp_l1            -0.00117   0.00239    -0.491 6.23e- 1</code></pre>
<p>Most of the above variables look like they are significant predictors of exposure. However, once again we are not interpreting the paramater coefficients of this model, we are only using it for prediction.</p>
<div class="sourceCode" id="cb514"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb514-1"><a href="some-approaches-for-confounding.html#cb514-1"></a>fhstv_incMI &lt;-fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb514-2"><a href="some-approaches-for-confounding.html#cb514-2"></a><span class="st">  </span><span class="kw">group_by</span>(randid) <span class="op">%&gt;%</span></span>
<span id="cb514-3"><a href="some-approaches-for-confounding.html#cb514-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_smokobs=</span><span class="kw">ifelse</span>(cursmoke <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,   <span class="co">###estimate the conditional probability that someone is unexposed or exposed from the model above</span></span>
<span id="cb514-4"><a href="some-approaches-for-confounding.html#cb514-4"></a>         <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(mod_tvIPW, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb514-5"><a href="some-approaches-for-confounding.html#cb514-5"></a>         <span class="kw">predict</span>(mod_tvIPW, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)),</span>
<span id="cb514-6"><a href="some-approaches-for-confounding.html#cb514-6"></a>         <span class="dt">w_i=</span><span class="dv">1</span><span class="op">/</span>p_smokobs,<span class="co">#### This is the first step</span></span>
<span id="cb514-7"><a href="some-approaches-for-confounding.html#cb514-7"></a>         <span class="dt">w=</span><span class="kw">cumprod</span>(w_i)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">### the second step gives us the cumulative product of the inverse probabilities over   time. </span></span>
<span id="cb514-8"><a href="some-approaches-for-confounding.html#cb514-8"></a><span class="st">         </span><span class="kw">ungroup</span>()</span>
<span id="cb514-9"><a href="some-approaches-for-confounding.html#cb514-9"></a></span>
<span id="cb514-10"><a href="some-approaches-for-confounding.html#cb514-10"></a>fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb514-11"><a href="some-approaches-for-confounding.html#cb514-11"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_w=</span><span class="kw">mean</span>(w),</span>
<span id="cb514-12"><a href="some-approaches-for-confounding.html#cb514-12"></a>            <span class="dt">min_w=</span><span class="kw">min</span>(w),</span>
<span id="cb514-13"><a href="some-approaches-for-confounding.html#cb514-13"></a>            <span class="dt">max_w=</span><span class="kw">max</span>(w),</span>
<span id="cb514-14"><a href="some-approaches-for-confounding.html#cb514-14"></a>            <span class="dt">sum_w=</span><span class="kw">sum</span>(w))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   mean_w min_w  max_w     sum_w
##    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;
## 1  1742.  1.08 18233. 19600277.</code></pre>
<p>Due to the cumulative product nature of these weights, we now see that the mean weight is much higher than before, while the maximum weight value is now over 18,000 meaning that particular observation will count as pver 18,000 observation in our analysis. This creates the possibility for very influential observations, due to weight inflation. One way to remedy this is to use stabilized weights, which involve a numerator that is also a probability of the actual exposure value at each time period. Unlike the denominator of the weights, the probability in the numerator will be a marginal probability of exposure or simply conditional on past exposure. We can even include our baseline covariates in the numerator model, however we will have to control for them in the final model if we do so. Here we will use probability of exposure values conditional on past exposure only for out numerators.</p>
<div class="sourceCode" id="cb516"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb516-1"><a href="some-approaches-for-confounding.html#cb516-1"></a>mod_tvIPWnum&lt;-<span class="kw">glm</span>(cursmoke<span class="op">~</span><span class="kw">ns</span>(time, <span class="dt">df=</span><span class="dv">2</span>)<span class="op">+</span>cursmoke_l1, <span class="dt">family=</span>binomial, <span class="dt">data=</span>fhstv_incMI)</span>
<span id="cb516-2"><a href="some-approaches-for-confounding.html#cb516-2"></a>mod_tvIPWnum <span class="op">%&gt;%</span></span>
<span id="cb516-3"><a href="some-approaches-for-confounding.html#cb516-3"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 4 × 5
##   term              estimate std.error statistic   p.value
##   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)          -2.91    0.0830     -35.0 6.46e-269
## 2 ns(time, df = 2)1    -2.00    0.176      -11.3 7.94e- 30
## 3 ns(time, df = 2)2    -1.46    0.119      -12.2 2.36e- 34
## 4 cursmoke_l1           5.77    0.0958      60.3 0</code></pre>
<div class="sourceCode" id="cb518"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb518-1"><a href="some-approaches-for-confounding.html#cb518-1"></a>fhstv_incMI &lt;-fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb518-2"><a href="some-approaches-for-confounding.html#cb518-2"></a><span class="st">  </span><span class="kw">group_by</span>(randid) <span class="op">%&gt;%</span></span>
<span id="cb518-3"><a href="some-approaches-for-confounding.html#cb518-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_smokobsnum=</span><span class="kw">ifelse</span>(cursmoke <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,   <span class="co">###estimate the conditional probability that someone is unexposed or exposed from the model above</span></span>
<span id="cb518-4"><a href="some-approaches-for-confounding.html#cb518-4"></a>         <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(mod_tvIPWnum, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb518-5"><a href="some-approaches-for-confounding.html#cb518-5"></a>         <span class="kw">predict</span>(mod_tvIPWnum, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)),</span>
<span id="cb518-6"><a href="some-approaches-for-confounding.html#cb518-6"></a>         <span class="dt">w_i=</span>p_smokobsnum<span class="op">/</span>p_smokobs,<span class="co">#### This is the first step</span></span>
<span id="cb518-7"><a href="some-approaches-for-confounding.html#cb518-7"></a>         <span class="dt">w=</span><span class="kw">cumprod</span>(w_i)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">### the second step gives us the cumulative product of the inverse probabilities over   time. </span></span>
<span id="cb518-8"><a href="some-approaches-for-confounding.html#cb518-8"></a><span class="st">         </span><span class="kw">ungroup</span>()</span>
<span id="cb518-9"><a href="some-approaches-for-confounding.html#cb518-9"></a></span>
<span id="cb518-10"><a href="some-approaches-for-confounding.html#cb518-10"></a></span>
<span id="cb518-11"><a href="some-approaches-for-confounding.html#cb518-11"></a>fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb518-12"><a href="some-approaches-for-confounding.html#cb518-12"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_w=</span><span class="kw">mean</span>(w),</span>
<span id="cb518-13"><a href="some-approaches-for-confounding.html#cb518-13"></a>            <span class="dt">min_w=</span><span class="kw">min</span>(w),</span>
<span id="cb518-14"><a href="some-approaches-for-confounding.html#cb518-14"></a>            <span class="dt">max_w=</span><span class="kw">max</span>(w),</span>
<span id="cb518-15"><a href="some-approaches-for-confounding.html#cb518-15"></a>            <span class="dt">sum_w=</span><span class="kw">sum</span>(w))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   mean_w min_w max_w sum_w
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  0.820 0.473  1.04 9230.</code></pre>
<p>A good rule of thumb for stabilized weights is that the mean of the weights should be around 1. Here we see that we are fairly lower than this. Including sex and age may improve our numerator model.</p>
<div class="sourceCode" id="cb520"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb520-1"><a href="some-approaches-for-confounding.html#cb520-1"></a>mod_tvIPWnum&lt;-<span class="kw">glm</span>(cursmoke<span class="op">~</span><span class="kw">ns</span>(time, <span class="dt">df=</span><span class="dv">2</span>)<span class="op">+</span>cursmoke_l1 <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">family=</span>binomial, <span class="dt">data=</span>fhstv_incMI)</span>
<span id="cb520-2"><a href="some-approaches-for-confounding.html#cb520-2"></a>mod_tvIPWnum <span class="op">%&gt;%</span></span>
<span id="cb520-3"><a href="some-approaches-for-confounding.html#cb520-3"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 × 5
##   term              estimate std.error statistic  p.value
##   &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)        -1.09     0.279      -3.91  9.30e- 5
## 2 ns(time, df = 2)1  -1.50     0.186      -8.09  5.99e-16
## 3 ns(time, df = 2)2  -1.14     0.126      -9.05  1.49e-19
## 4 cursmoke_l1         5.73     0.0975     58.8   0       
## 5 age                -0.0381   0.00466    -8.18  2.88e-16
## 6 sex                 0.0636   0.0775      0.820 4.12e- 1</code></pre>
<div class="sourceCode" id="cb522"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb522-1"><a href="some-approaches-for-confounding.html#cb522-1"></a>fhstv_incMI &lt;-fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb522-2"><a href="some-approaches-for-confounding.html#cb522-2"></a><span class="st">  </span><span class="kw">group_by</span>(randid) <span class="op">%&gt;%</span></span>
<span id="cb522-3"><a href="some-approaches-for-confounding.html#cb522-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_smokobsnum=</span><span class="kw">ifelse</span>(cursmoke <span class="op">==</span><span class="st"> </span><span class="dv">0</span>,   <span class="co">###estimate the conditional probability that someone is unexposed or exposed from the model above</span></span>
<span id="cb522-4"><a href="some-approaches-for-confounding.html#cb522-4"></a>         <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(mod_tvIPWnum, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb522-5"><a href="some-approaches-for-confounding.html#cb522-5"></a>         <span class="kw">predict</span>(mod_tvIPWnum, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)),</span>
<span id="cb522-6"><a href="some-approaches-for-confounding.html#cb522-6"></a>         <span class="dt">w_i=</span>p_smokobsnum<span class="op">/</span>p_smokobs,<span class="co">#### This is the first step</span></span>
<span id="cb522-7"><a href="some-approaches-for-confounding.html#cb522-7"></a>         <span class="dt">w=</span><span class="kw">cumprod</span>(w_i)) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">### the second step gives us the cumulative product of the inverse probabilities over   time. </span></span>
<span id="cb522-8"><a href="some-approaches-for-confounding.html#cb522-8"></a><span class="st">         </span><span class="kw">ungroup</span>()</span>
<span id="cb522-9"><a href="some-approaches-for-confounding.html#cb522-9"></a></span>
<span id="cb522-10"><a href="some-approaches-for-confounding.html#cb522-10"></a></span>
<span id="cb522-11"><a href="some-approaches-for-confounding.html#cb522-11"></a>fhstv_incMI <span class="op">%&gt;%</span></span>
<span id="cb522-12"><a href="some-approaches-for-confounding.html#cb522-12"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_w=</span><span class="kw">mean</span>(w),</span>
<span id="cb522-13"><a href="some-approaches-for-confounding.html#cb522-13"></a>            <span class="dt">min_w=</span><span class="kw">min</span>(w),</span>
<span id="cb522-14"><a href="some-approaches-for-confounding.html#cb522-14"></a>            <span class="dt">max_w=</span><span class="kw">max</span>(w),</span>
<span id="cb522-15"><a href="some-approaches-for-confounding.html#cb522-15"></a>            <span class="dt">sum_w=</span><span class="kw">sum</span>(w))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   mean_w min_w max_w  sum_w
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1   1.02 0.986  1.11 11488.</code></pre>
<p>We now see we are much closer to a mean weight of one and the weight range is quite narrow, meaning the chance for influential observations is not high. We now git our Marginal Structural Cox model for MI hospitalizations. Note that because we included age and sex in our weights numerator model we have to adjust for them in this outcome model, therefore it is not Marginal with respect to them, only with respect to BMI and systolic blood pressure</p>
<div class="sourceCode" id="cb524"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb524-1"><a href="some-approaches-for-confounding.html#cb524-1"></a>coxph_modtvMIipw &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(time, timemi2, hospmitv) <span class="op">~</span><span class="st"> </span></span>
<span id="cb524-2"><a href="some-approaches-for-confounding.html#cb524-2"></a><span class="st">                                </span>cursmoke <span class="op">+</span></span>
<span id="cb524-3"><a href="some-approaches-for-confounding.html#cb524-3"></a><span class="st">                                </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">weights=</span>w, <span class="dt">cluster=</span>randid,</span>
<span id="cb524-4"><a href="some-approaches-for-confounding.html#cb524-4"></a>                              <span class="dt">data =</span> fhstv_incMI)</span>
<span id="cb524-5"><a href="some-approaches-for-confounding.html#cb524-5"></a>coxph_modtvMIipw <span class="op">%&gt;%</span></span>
<span id="cb524-6"><a href="some-approaches-for-confounding.html#cb524-6"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 3 × 6
##   term     estimate std.error robust.se statistic  p.value
##   &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 cursmoke   0.485    0.105     0.105        4.59 4.37e- 6
## 2 age        0.0460   0.00601   0.00617      7.45 9.28e-14
## 3 sex       -1.11     0.108     0.109      -10.1  4.58e-24</code></pre>
<div class="sourceCode" id="cb526"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb526-1"><a href="some-approaches-for-confounding.html#cb526-1"></a>coxph_modtvMIipw <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb526-2"><a href="some-approaches-for-confounding.html#cb526-2"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb526-3"><a href="some-approaches-for-confounding.html#cb526-3"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &#39;cursmoke&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb526-4"><a href="some-approaches-for-confounding.html#cb526-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb526-5"><a href="some-approaches-for-confounding.html#cb526-5"></a>         <span class="dt">low_ci =</span> (estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>robust.se), </span>
<span id="cb526-6"><a href="some-approaches-for-confounding.html#cb526-6"></a>         <span class="dt">high_ci =</span> (estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>robust.se), </span>
<span id="cb526-7"><a href="some-approaches-for-confounding.html#cb526-7"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb526-8"><a href="some-approaches-for-confounding.html#cb526-8"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb526-9"><a href="some-approaches-for-confounding.html#cb526-9"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.62   1.32    2.00</code></pre>
<p>Based on the results of this model and using the correct interpretation we can deduce that the HR comparing what would have happened if everybody was always continuously a smoker (for the duration of follow-up), to what would have happened if no one was ever a smoker is 1.62 (95% CI: 1.32 - 2.00).</p>
<p>The HR is now lower that the conditional model, and although they are not directly comparable, the difference could be explained by the fact that we are no longer blocking a potentially negative effect of smoking on risk of MI hospitalization mediated through BMI (smoking usually has a negative association with BMI overall). Another potential explanation is that the conditional Cox model adjusting for BMI and blood pressure, also induced collider bias through unmeasured common causes between BMI and systolic blood pressure and the outcome, leading to bias away from the null. These are all issues we have to take in mind when choosing the estimation approach we think is more likely to lead to unbiased results. IPW is advantageous compared to traditional regression approaches to control for confounding in the presence of exposure-confounder feedback, however it comes at the cost of additional model(s). Misspecifying any of the models involved could also lead to bias, and as we have seen in the complex time-varying setting, weights may not always behave well. We could improve our weight estimation using machine learning algorithms that make fewer to no distributional and parametric assumptions, thus minimizing the potential for misspecification of weight models.</p>
</div>
<div id="propensity-scores" class="section level2">
<h2><span class="header-section-number">8.3</span> Propensity scores</h2>
<p>IPW is technically part of a general approach to adjust for confounding relying on measures for the probability of exposure known as propensity scores. In other words rather than adjusting for potential confounders directly, we adjust for the propensity of exposure given observed values of those potential confounders. Propensity scores can be used as weights (like in ipw), can be stratified upon, entered as a covariate in a model, or can be used as a matching variable for covariate adjustment. Each participant (or onbservation in the data) essentially receives a <em>score</em> for their propensity to be exposed given their covariate values. This score is equal to the probability of exposure given covariate values <span class="math inline">\(Pr[X=1|C]\)</span> where <span class="math inline">\(X\)</span> is the exposure of interest (<span class="math inline">\(X=1\)</span> for exposed and <span class="math inline">\(X=0\)</span> for unexposed), and <span class="math inline">\(C\)</span> is a vector of covariates (potential confounders).</p>
<p><em>Applied exercise: Propensity scores for confounding adjustment</em></p>
<p>Using the FHS cohort data answer the following questions with respect to confounding of the potential effect of smoking on mortality:</p>
<ol style="list-style-type: decimal">
<li>Estimate the propensity score for exposure based on age and sex in the time-invariant dataset. Create quartiles for the propensity score and stratify on it. What is the relationship between smoking and baseline and hazard of mortality within these strata? How does it compare to the conditional Cox model adjusting for age and sex?</li>
<li>Fit a Cox model with the propensity score in the model. How do these results compare to the ones above?</li>
</ol>
<p><em>Applied exercise: Example code</em></p>
<ol style="list-style-type: decimal">
<li><strong>Estimate the propensity score for exposure based on age and sex in the time-invariant dataset. Create quartiles for the propensity score and stratify on it. What is the relationship between smoking at baseline and hazard of mortality within these strata? How does it compare to the conditional Cox model adjusting for age and sex?</strong></li>
</ol>
<p>Estimating the propensity score is actually very similar to what we did above to estimate IP weights. We will fit a logistic model for the probability of exposure and use it to generate predictions for the propensity score:</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="some-approaches-for-confounding.html#cb528-1"></a>model_PS&lt;-<span class="kw">glm</span>(cursmoke<span class="op">~+</span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">family=</span><span class="st">&#39;binomial&#39;</span>, <span class="dt">data=</span>fhs_first)</span>
<span id="cb528-2"><a href="some-approaches-for-confounding.html#cb528-2"></a>model_PS <span class="op">%&gt;%</span></span>
<span id="cb528-3"><a href="some-approaches-for-confounding.html#cb528-3"></a><span class="st">  </span><span class="kw">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 3 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   3.84     0.218        17.6 1.37e-69
## 2 age          -0.0514   0.00370     -13.9 8.06e-44
## 3 sex          -0.839    0.0634      -13.2 6.04e-40</code></pre>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="some-approaches-for-confounding.html#cb530-1"></a>fhs_first &lt;-fhs_first <span class="op">%&gt;%</span></span>
<span id="cb530-2"><a href="some-approaches-for-confounding.html#cb530-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ps_smok=</span><span class="kw">predict</span>(model_PS, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>))</span>
<span id="cb530-3"><a href="some-approaches-for-confounding.html#cb530-3"></a></span>
<span id="cb530-4"><a href="some-approaches-for-confounding.html#cb530-4"></a>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb530-5"><a href="some-approaches-for-confounding.html#cb530-5"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_ps=</span><span class="kw">mean</span>(ps_smok),</span>
<span id="cb530-6"><a href="some-approaches-for-confounding.html#cb530-6"></a>            <span class="dt">max_ps=</span><span class="kw">max</span>(ps_smok),</span>
<span id="cb530-7"><a href="some-approaches-for-confounding.html#cb530-7"></a>            <span class="dt">min_ps=</span><span class="kw">min</span>(ps_smok),</span>
<span id="cb530-8"><a href="some-approaches-for-confounding.html#cb530-8"></a>            <span class="dt">sum_ps=</span><span class="kw">sum</span>(ps_smok))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   mean_ps max_ps min_ps sum_ps
##     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1   0.492  0.787  0.192  2181.</code></pre>
<p>You may have noticed that unlike in IPW where we wanted to conditional probability of the value of exposure each participant had (i.e the probability that they were exposed if exposed and the probability that they were unexposed if unexposed) here we want the probability of exposure for everyone. This slight difference has a consequence in the interpretation of our findings later. Therefore the PS is a continuous variable with a possible range of 0 to 1 and the sum of the propensity score should equal the number of exposed individuals in the dataset. Given the continuous nature of the PS it is difficult to stratify on it, as any given exact value may only have one participant with that value. In our case, since we are only predicting based on age and sex, participants with the same age and sex will have the same value, however those may still be small counts in each possible stratum.</p>
<div class="sourceCode" id="cb532"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb532-1"><a href="some-approaches-for-confounding.html#cb532-1"></a>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb532-2"><a href="some-approaches-for-confounding.html#cb532-2"></a><span class="st">  </span><span class="kw">select</span>(ps_smok) <span class="op">%&gt;%</span></span>
<span id="cb532-3"><a href="some-approaches-for-confounding.html#cb532-3"></a><span class="st">  </span><span class="kw">head</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 × 1
##   ps_smok
##     &lt;dbl&gt;
## 1   0.731
## 2   0.450
## 3   0.631
## 4   0.274
## 5   0.450
## 6   0.488</code></pre>
<p>We will therefore limit the possible number of strata and hopefuly increase the counts in each stratum by creating quartiles for the PS:</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="some-approaches-for-confounding.html#cb534-1"></a>fhs_first&lt;-<span class="st"> </span>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb534-2"><a href="some-approaches-for-confounding.html#cb534-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ps_smokq=</span><span class="kw">cut</span>(ps_smok, <span class="dt">breaks=</span><span class="kw">c</span>(<span class="kw">quantile</span>(ps_smok, <span class="dt">probs =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.25</span>))), </span>
<span id="cb534-3"><a href="some-approaches-for-confounding.html#cb534-3"></a>      <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;Q1&quot;</span>,<span class="st">&quot;Q2&quot;</span>,<span class="st">&quot;Q3&quot;</span>,<span class="st">&quot;Q4&quot;</span>), <span class="dt">include.lowest=</span><span class="ot">TRUE</span>))</span></code></pre></div>
<p>If we now fit our models in each of the strate defined by the quartiles:</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="some-approaches-for-confounding.html#cb535-1"></a>fhs_firstPSQ1&lt;-<span class="st"> </span>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb535-2"><a href="some-approaches-for-confounding.html#cb535-2"></a><span class="st">  </span><span class="kw">filter</span>(ps_smokq<span class="op">==</span><span class="st">&#39;Q1&#39;</span>)</span>
<span id="cb535-3"><a href="some-approaches-for-confounding.html#cb535-3"></a></span>
<span id="cb535-4"><a href="some-approaches-for-confounding.html#cb535-4"></a>coxph_modPSQ1 &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timemi, hospmi) <span class="op">~</span><span class="st"> </span>cursmoke, </span>
<span id="cb535-5"><a href="some-approaches-for-confounding.html#cb535-5"></a>                    <span class="dt">data =</span> fhs_firstPSQ1)</span>
<span id="cb535-6"><a href="some-approaches-for-confounding.html#cb535-6"></a>coxph_modPSQ1 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb535-7"><a href="some-approaches-for-confounding.html#cb535-7"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb535-8"><a href="some-approaches-for-confounding.html#cb535-8"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb535-9"><a href="some-approaches-for-confounding.html#cb535-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb535-10"><a href="some-approaches-for-confounding.html#cb535-10"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb535-11"><a href="some-approaches-for-confounding.html#cb535-11"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb535-12"><a href="some-approaches-for-confounding.html#cb535-12"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb535-13"><a href="some-approaches-for-confounding.html#cb535-13"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb535-14"><a href="some-approaches-for-confounding.html#cb535-14"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.21  0.784    1.88</code></pre>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="some-approaches-for-confounding.html#cb537-1"></a>fhs_firstPSQ2&lt;-<span class="st"> </span>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb537-2"><a href="some-approaches-for-confounding.html#cb537-2"></a><span class="st">  </span><span class="kw">filter</span>(ps_smokq<span class="op">==</span><span class="st">&#39;Q2&#39;</span>)</span>
<span id="cb537-3"><a href="some-approaches-for-confounding.html#cb537-3"></a></span>
<span id="cb537-4"><a href="some-approaches-for-confounding.html#cb537-4"></a>coxph_modPSQ2 &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timemi, hospmi) <span class="op">~</span><span class="st"> </span>cursmoke, </span>
<span id="cb537-5"><a href="some-approaches-for-confounding.html#cb537-5"></a>                    <span class="dt">data =</span> fhs_firstPSQ2)</span>
<span id="cb537-6"><a href="some-approaches-for-confounding.html#cb537-6"></a>coxph_modPSQ2 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb537-7"><a href="some-approaches-for-confounding.html#cb537-7"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb537-8"><a href="some-approaches-for-confounding.html#cb537-8"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb537-9"><a href="some-approaches-for-confounding.html#cb537-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb537-10"><a href="some-approaches-for-confounding.html#cb537-10"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb537-11"><a href="some-approaches-for-confounding.html#cb537-11"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb537-12"><a href="some-approaches-for-confounding.html#cb537-12"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb537-13"><a href="some-approaches-for-confounding.html#cb537-13"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb537-14"><a href="some-approaches-for-confounding.html#cb537-14"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.35  0.902    2.02</code></pre>
<div class="sourceCode" id="cb539"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb539-1"><a href="some-approaches-for-confounding.html#cb539-1"></a>fhs_firstPSQ3&lt;-<span class="st"> </span>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb539-2"><a href="some-approaches-for-confounding.html#cb539-2"></a><span class="st">  </span><span class="kw">filter</span>(ps_smokq<span class="op">==</span><span class="st">&#39;Q3&#39;</span>)</span>
<span id="cb539-3"><a href="some-approaches-for-confounding.html#cb539-3"></a></span>
<span id="cb539-4"><a href="some-approaches-for-confounding.html#cb539-4"></a>coxph_modPSQ3 &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timemi, hospmi) <span class="op">~</span><span class="st"> </span>cursmoke, </span>
<span id="cb539-5"><a href="some-approaches-for-confounding.html#cb539-5"></a>                    <span class="dt">data =</span> fhs_firstPSQ3)</span>
<span id="cb539-6"><a href="some-approaches-for-confounding.html#cb539-6"></a>coxph_modPSQ3 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb539-7"><a href="some-approaches-for-confounding.html#cb539-7"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb539-8"><a href="some-approaches-for-confounding.html#cb539-8"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb539-9"><a href="some-approaches-for-confounding.html#cb539-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb539-10"><a href="some-approaches-for-confounding.html#cb539-10"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb539-11"><a href="some-approaches-for-confounding.html#cb539-11"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb539-12"><a href="some-approaches-for-confounding.html#cb539-12"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb539-13"><a href="some-approaches-for-confounding.html#cb539-13"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb539-14"><a href="some-approaches-for-confounding.html#cb539-14"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.38  0.922    2.05</code></pre>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="some-approaches-for-confounding.html#cb541-1"></a>fhs_firstPSQ4&lt;-<span class="st"> </span>fhs_first <span class="op">%&gt;%</span></span>
<span id="cb541-2"><a href="some-approaches-for-confounding.html#cb541-2"></a><span class="st">  </span><span class="kw">filter</span>(ps_smokq<span class="op">==</span><span class="st">&#39;Q4&#39;</span>)</span>
<span id="cb541-3"><a href="some-approaches-for-confounding.html#cb541-3"></a></span>
<span id="cb541-4"><a href="some-approaches-for-confounding.html#cb541-4"></a>coxph_modPSQ4 &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timemi, hospmi) <span class="op">~</span><span class="st"> </span>cursmoke, </span>
<span id="cb541-5"><a href="some-approaches-for-confounding.html#cb541-5"></a>                    <span class="dt">data =</span> fhs_firstPSQ4)</span>
<span id="cb541-6"><a href="some-approaches-for-confounding.html#cb541-6"></a>coxph_modPSQ4<span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb541-7"><a href="some-approaches-for-confounding.html#cb541-7"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb541-8"><a href="some-approaches-for-confounding.html#cb541-8"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb541-9"><a href="some-approaches-for-confounding.html#cb541-9"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb541-10"><a href="some-approaches-for-confounding.html#cb541-10"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb541-11"><a href="some-approaches-for-confounding.html#cb541-11"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb541-12"><a href="some-approaches-for-confounding.html#cb541-12"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb541-13"><a href="some-approaches-for-confounding.html#cb541-13"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb541-14"><a href="some-approaches-for-confounding.html#cb541-14"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.31  0.930    1.83</code></pre>
<p>The individual HR from each stratum are all higher than the original unadjusted, but not quite as high as the overall adjusted model. Furthermore, we see that CIs are wider (all include the null) as we lose power when looking in each individual stratum. Expanding the number of categories for the PS (e.g. deciles) may improve our control for confoudning, but it will come at the cost of additional loss of power</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Fit a Cox model with the propensity score in the model. How do these results compare to the ones above?</strong></li>
</ol>
<p>We can instead fit a model including the original continuous PS as a covariate in the model and maintain our original power:</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="some-approaches-for-confounding.html#cb543-1"></a>coxph_modPS &lt;-<span class="st"> </span><span class="kw">coxph</span>(<span class="kw">Surv</span>(timemi, hospmi) <span class="op">~</span><span class="st"> </span>cursmoke <span class="op">+</span><span class="st"> </span>ps_smok, </span>
<span id="cb543-2"><a href="some-approaches-for-confounding.html#cb543-2"></a>                    <span class="dt">data =</span> fhs_first)</span>
<span id="cb543-3"><a href="some-approaches-for-confounding.html#cb543-3"></a>coxph_modPS <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb543-4"><a href="some-approaches-for-confounding.html#cb543-4"></a><span class="st">  </span><span class="kw">tidy</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb543-5"><a href="some-approaches-for-confounding.html#cb543-5"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> &quot;cursmoke&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb543-6"><a href="some-approaches-for-confounding.html#cb543-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hr =</span> <span class="kw">exp</span>(estimate),</span>
<span id="cb543-7"><a href="some-approaches-for-confounding.html#cb543-7"></a>         <span class="dt">low_ci =</span> estimate <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb543-8"><a href="some-approaches-for-confounding.html#cb543-8"></a>         <span class="dt">high_ci =</span> estimate <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>std.error, </span>
<span id="cb543-9"><a href="some-approaches-for-confounding.html#cb543-9"></a>         <span class="dt">low_hr =</span> <span class="kw">exp</span>(low_ci), </span>
<span id="cb543-10"><a href="some-approaches-for-confounding.html#cb543-10"></a>         <span class="dt">high_hr =</span> <span class="kw">exp</span>(high_ci)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb543-11"><a href="some-approaches-for-confounding.html#cb543-11"></a><span class="st">  </span><span class="kw">select</span>(term, hr, low_hr, high_hr)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##   term        hr low_hr high_hr
##   &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
## 1 cursmoke  1.34   1.10    1.62</code></pre>
<p>We see that our CIs are now less wide, however our estimate (though similar) does not exactly match the one from the original adjusted model, nor the IP weighted model. Again the interpretation of the HR from this model is different from those two and in the case of IPW it has to do with the nuanced difference of focusing on the probability of being exposed, rather than the probability of having the exposure value each one had (i.e. exposed or unexposed). The correct interpretation of this HR is as the effect of exposure in the exposed. In other words it is the HR comparing what would have happened if the exposed were exposed (what actually happened) to what would have happened if the exposed were unexposed. By contrast remember that the interpreataion of the HR in the case of IPW was the HR comparing what would have happened if everyone was exposed to what would have happened if nobody was exposed.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-brookhart2013propensity">
<p>Brookhart, M Alan, Richard Wyss, J Bradley Layton, and Til Stürmer. 2013. “Propensity Score Methods for Confounding Control in Nonexperimental Research.” <em>Circulation: Cardiovascular Quality and Outcomes</em> 6 (5): 604–11.</p>
</div>
<div id="ref-cole2008constructing">
<p>Cole, Stephen R, and Miguel A Hernán. 2008. “Constructing Inverse Probability Weights for Marginal Structural Models.” <em>American Journal of Epidemiology</em> 168 (6): 656–64.</p>
</div>
<div id="ref-greenland1999confounding">
<p>Greenland, Sander, Judea Pearl, and James M Robins. 1999. “Confounding and Collapsibility in Causal Inference.” <em>Statistical Science</em> 14 (1): 29–46.</p>
</div>
<div id="ref-hernanch12">
<p>Hernán, Miguel A, and James M Robins. 2020a. “IP Weighting and Marginal Structural Models.” In. Boca Raton: Chapman &amp; Hall/CRC.</p>
</div>
<div id="ref-hernanch15">
<p>Hernán, Miguel A, and James M Robins. 2020b. “Outcome Regression and Propensity Scores.” In. Boca Raton: Chapman &amp; Hall/CRC.</p>
</div>
<div id="ref-hernanch20">
<p>Hernán, Miguel A, and James M Robins. 2020c. “Treatment-Confounder Feedback.” In. Boca Raton: Chapman &amp; Hall/CRC.</p>
</div>
<div id="ref-lee2010improving">
<p>Lee, Brian K, Justin Lessler, and Elizabeth A Stuart. 2010. “Improving Propensity Score Weighting Using Machine Learning.” <em>Statistics in Medicine</em> 29 (3): 337–46.</p>
</div>
<div id="ref-westreich2010propensity">
<p>Westreich, Daniel, Justin Lessler, and Michele Jonsson Funk. 2010. “Propensity Score Estimation: Machine Learning and Classification Methods as Alternatives to Logistic Regression.” <em>Journal of Clinical Epidemiology</em> 63 (8): 826.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="longitudinal-cohort-study-designs.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixed-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["adv_epi_analysis.pdf", "adv_epi_analysis.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
